{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "07MISeqn_913",
        "outputId": "2c96100f-c8ca-42e7-8e3d-82e82c6b3192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1vAuTUfkeRX045AMhUPcguxwov2dqAVtJ\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'my_dataset.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-05e1dd6a02ff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_dataset.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_dataset.zip'"
          ]
        }
      ],
      "source": [
        "!pip install -q gdown\n",
        "!gdown --id 1vAuTUfkeRX045AMhUPcguxwov2dqAVtJ --output my_dataset.zip\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "with gzip.open('my_dataset.zip', 'rb') as f_in:\n",
        "    with open('my_dataset', 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open(\"my_dataset\", \"r:\") as tar:\n",
        "    tar.extractall(\"my_dataset_extracted\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install required packages\n",
        "!pip install gigagan-pytorch==0.2.20 fvcore torch torchvision validators"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA77CP0vADzQ",
        "outputId": "89f44d82-d67f-4335-999c-9720e3f65b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gigagan-pytorch==0.2.20 in /usr/local/lib/python3.11/dist-packages (0.2.20)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (1.6.0)\n",
            "Requirement already satisfied: beartype in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (0.20.2)\n",
            "Requirement already satisfied: einops>=0.6 in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (0.8.1)\n",
            "Requirement already satisfied: ema-pytorch in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (0.7.7)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (0.8.0)\n",
            "Requirement already satisfied: numerize in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (0.12)\n",
            "Requirement already satisfied: open-clip-torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (2.32.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gigagan-pytorch==0.2.20) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2024.11.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (6.3.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (0.5.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (1.0.15)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->gigagan-pytorch==0.2.20) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->gigagan-pytorch==0.2.20) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: kornia_rs>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from kornia->gigagan-pytorch==0.2.20) (0.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2.32.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from gigagan_pytorch import GigaGAN\n",
        "import logging\n",
        "import json\n",
        "import time\n",
        "import torchvision.utils as vutils\n",
        "from fvcore.nn import parameter_count\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.cuda.amp import autocast"
      ],
      "metadata": {
        "id": "EQVY3fEgAGLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNCONDITIONAL = True\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 4\n",
        "TRAINING_STEPS = 1000\n",
        "FINETUNE_STEPS = 100\n",
        "DATA_PATH = \"my_dataset_extracted/GigaGAN_cond_imagenet256\"\n",
        "SAVE_DIR = \"gigagan_pruned_results\"\n",
        "MODEL_FOLDER = \"gigagan_pruning_checkpoints\"\n",
        "RESULTS_FOLDER = \"gigagan_pruning_results\"\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(\"profiling_results\", exist_ok=True)\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "    handlers=[logging.FileHandler(\"gigagan_training.log\"), logging.StreamHandler()]\n",
        ")\n",
        "logger = logging.getLogger(\"gigagan\")"
      ],
      "metadata": {
        "id": "8nkFLVHqAGIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "def load_imagenet_dataset(path):\n",
        "    dataset = datasets.ImageFolder(root=path, transform=transform)\n",
        "    logger.info(f\"Loaded dataset with {len(dataset)} samples from {path}\")\n",
        "    return dataset\n",
        "\n",
        "def collate_images_only(batch):\n",
        "    images, _ = zip(*batch)\n",
        "    return torch.stack(images)"
      ],
      "metadata": {
        "id": "j1Ny_fN-AGGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_dataloader(dataloader, num_batches=10):\n",
        "    logger.info(f\"Profiling dataloader for {num_batches} batches...\")\n",
        "    batch_times = []\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    if use_cuda:\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        start_memory = torch.cuda.memory_allocated() / (1024 * 1024)\n",
        "    else:\n",
        "        start_memory = 0\n",
        "\n",
        "    start = time.time()\n",
        "    for i, images in enumerate(dataloader):\n",
        "        if i == num_batches:\n",
        "            break\n",
        "    total_time = time.time() - start\n",
        "    avg_time = total_time / num_batches\n",
        "    peak_memory = torch.cuda.max_memory_allocated() / (1024 * 1024) if use_cuda else 0\n",
        "\n",
        "    stats = {\n",
        "        \"avg_batch_time_sec\": avg_time,\n",
        "        \"peak_memory_mb\": peak_memory,\n",
        "        \"start_memory_mb\": start_memory\n",
        "    }\n",
        "\n",
        "    with open(\"profiling_results/dataloader_stats.json\", \"w\") as f:\n",
        "        json.dump(stats, f, indent=2)\n",
        "\n",
        "    logger.info(f\"Dataloader avg time: {avg_time:.4f}s, peak memory: {peak_memory:.2f} MB\")\n",
        "    return stats"
      ],
      "metadata": {
        "id": "60gaIemcAF_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_model():\n",
        "    logger.info(\"Setting up GigaGAN (Unconditional)...\")\n",
        "    gan = GigaGAN(\n",
        "        train_upsampler=True,\n",
        "        generator=dict(\n",
        "            dim=32,\n",
        "            style_network=dict(dim=64, depth=4),\n",
        "            image_size=IMAGE_SIZE,\n",
        "            input_image_size=64,\n",
        "            unconditional=UNCONDITIONAL\n",
        "        ),\n",
        "        discriminator=dict(\n",
        "            dim_capacity=16,\n",
        "            dim_max=512,\n",
        "            image_size=IMAGE_SIZE,\n",
        "            multiscale_input_resolutions=(128,),\n",
        "            num_skip_layers_excite=4,\n",
        "            unconditional=UNCONDITIONAL\n",
        "        ),\n",
        "        learning_rate=1e-5,\n",
        "        amp=True,\n",
        "        model_folder=MODEL_FOLDER,\n",
        "        results_folder=RESULTS_FOLDER\n",
        "    ).cuda()\n",
        "\n",
        "    total_params = sum(p.numel() for p in gan.parameters())\n",
        "    trainable_params = sum(p.numel() for p in gan.parameters() if p.requires_grad)\n",
        "    model_size_mb = sum(p.numel() * p.element_size() for p in gan.parameters()) / 1024**2\n",
        "\n",
        "    logger.info(f\"Model initialized: {total_params:,} params ({model_size_mb:.2f} MB)\")\n",
        "    return gan"
      ],
      "metadata": {
        "id": "bxypB-DnAQ7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(gan, dataloader, steps, save_name=\"model-final.ckpt\"):\n",
        "    gan.set_dataloader(dataloader)\n",
        "    logger.info(f\"Training for {steps} steps (AMP enabled)\")\n",
        "    with autocast():\n",
        "        gan(steps=steps, grad_accum_every=8)\n",
        "    save_path = os.path.join(MODEL_FOLDER, save_name)\n",
        "    gan.save(save_path)\n",
        "    logger.info(f\"Model saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "RwWJVHQVAQ4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(model, label):\n",
        "    gen_params = sum(p.numel() for p in model.unwrapped_G.parameters())\n",
        "    disc_params = sum(p.numel() for p in model.unwrapped_D.parameters())\n",
        "    total = gen_params + disc_params\n",
        "    logger.info(f\"{label} Generator: {gen_params/1e6:.2f}M, Discriminator: {disc_params/1e6:.2f}M, Total: {total/1e6:.2f}M\")\n",
        "\n",
        "def prune_gigagan_model(model, amount=0.3, target=\"both\"):\n",
        "    logger.info(f\"Pruning GigaGAN ({target}) with {amount*100:.0f}% sparsity\")\n",
        "    if target in [\"generator\", \"both\"]:\n",
        "        for _, module in model.unwrapped_G.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                prune.ln_structured(module, name=\"weight\", amount=amount, n=1, dim=0)\n",
        "    if target in [\"discriminator\", \"both\"]:\n",
        "        for _, module in model.unwrapped_D.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                prune.ln_structured(module, name=\"weight\", amount=amount, n=1, dim=0)\n",
        "    logger.info(\"Pruning complete.\")\n",
        "\n",
        "def remove_pruning_reparam(model, target=\"both\"):\n",
        "    logger.info(\"Stripping pruning reparametrizations...\")\n",
        "    for net in ([model.unwrapped_G] if target == \"generator\" else [model.unwrapped_D, model.unwrapped_G]):\n",
        "        for _, module in net.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d) and hasattr(module, \"weight_mask\"):\n",
        "                prune.remove(module, \"weight\")"
      ],
      "metadata": {
        "id": "rbt2mCaLAVrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(gan, num_images=3):\n",
        "    input_size = gan.unwrapped_G.input_image_size\n",
        "    for i in range(num_images):\n",
        "        noise = torch.randn(1, 3, input_size, input_size).cuda()\n",
        "        with torch.no_grad(), autocast():\n",
        "            img = gan.generate(lowres_image=noise)[0].cpu()\n",
        "        img = torch.nan_to_num(img, nan=0.0).clamp(-1, 1)\n",
        "        img = (img * 0.5 + 0.5)\n",
        "        vutils.save_image(img, f\"{SAVE_DIR}/generated_{i}.png\")\n",
        "        logger.info(f\"Saved: {SAVE_DIR}/generated_{i}.png\")"
      ],
      "metadata": {
        "id": "YsHx-vq5AVoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_nonzero_params(model, label):\n",
        "    def count_nonzero(p):\n",
        "        return (p != 0).sum().item()\n",
        "\n",
        "    gen_nonzero = sum(count_nonzero(p) for p in model.unwrapped_G.parameters() if p.requires_grad)\n",
        "    disc_nonzero = sum(count_nonzero(p) for p in model.unwrapped_D.parameters() if p.requires_grad)\n",
        "    total = gen_nonzero + disc_nonzero\n",
        "\n",
        "    logger.info(f\"{label} Generator: {gen_nonzero/1e6:.2f}M nonzero, Discriminator: {disc_nonzero/1e6:.2f}M nonzero, Total: {total/1e6:.2f}M nonzero\")\n",
        "    return gen_nonzero, disc_nonzero"
      ],
      "metadata": {
        "id": "UoQ60XXwD6Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gigagan():\n",
        "    dataset = load_imagenet_dataset(DATA_PATH)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, collate_fn=collate_images_only)\n",
        "    profile_dataloader(dataloader)\n",
        "    gan = setup_model()\n",
        "    count_params(gan, \"Initial (Unpruned)\")\n",
        "    train_model(gan, dataloader, steps=TRAINING_STEPS, save_name=\"model-unpruned.ckpt\")\n",
        "\n",
        "# ---------------------------- Phase 2: Prune + Fine-tune ----------------------------\n",
        "def prune_and_finetune_gigagan():\n",
        "    dataset = load_imagenet_dataset(DATA_PATH)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, collate_fn=collate_images_only)\n",
        "    gan = setup_model()\n",
        "    gan.load(os.path.join(MODEL_FOLDER, \"model-unpruned.ckpt\"))\n",
        "    count_params(gan, \"Before Pruning\")\n",
        "    prune_gigagan_model(gan, amount=0.3, target=\"both\")\n",
        "    remove_pruning_reparam(gan, target=\"both\")\n",
        "    count_params(gan, \"After Pruning + Reparam Removal\")\n",
        "    gan.unwrapped_G.load_state_dict(gan.unwrapped_G.state_dict())  # safe sync for EMA\n",
        "    train_model(gan, dataloader, steps=FINETUNE_STEPS, save_name=\"model-pruned.ckpt\")\n",
        "    generate_and_save_images(gan)\n",
        "\n",
        "def iterative_pruning_workflow(iterations=5, initial_prune=0.1):\n",
        "    dataset = load_imagenet_dataset(DATA_PATH)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, collate_fn=collate_images_only)\n",
        "    profile_dataloader(dataloader)\n",
        "\n",
        "    gan = setup_model()\n",
        "    train_model(gan, dataloader, steps=TRAINING_STEPS, save_name=\"model-unpruned.ckpt\")\n",
        "    gan.load(os.path.join(MODEL_FOLDER, \"model-unpruned.ckpt\"))\n",
        "\n",
        "    cumulative_prune = 1.0\n",
        "    for i in range(iterations):\n",
        "        prune_step = 1 - initial_prune\n",
        "        cumulative_prune *= prune_step\n",
        "        logger.info(f\"Iteration {i+1}: Pruning to cumulative {(1-cumulative_prune)*100:.1f}%\")\n",
        "\n",
        "        prune_gigagan_model(gan, amount=initial_prune, target=\"both\")\n",
        "        remove_pruning_reparam(gan, target=\"both\")\n",
        "        count_params(gan, f\"Post-Prune Iteration {i+1}\")\n",
        "\n",
        "        gan.unwrapped_G.load_state_dict(gan.unwrapped_G.state_dict())\n",
        "        train_model(gan, dataloader, steps=FINETUNE_STEPS, save_name=f\"model-pruned-{i+1}.ckpt\")\n",
        "\n",
        "    generate_and_save_images(gan)"
      ],
      "metadata": {
        "id": "m4rjDyElAa09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan = setup_model()\n",
        "# gan.load(os.path.join(MODEL_FOLDER, \"model-unpruned.ckpt\"))\n",
        "# count_nonzero_params(gan, \"After Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJO4b8URFQbA",
        "outputId": "02d2f65d-ddc3-4028-96c3-28a95512c69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Generator: 43.71M\n",
            "Discriminator: 30.74M\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gigagan()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "8auan23WAdXs",
        "outputId": "1d75bd47-7a7c-44bb-a125-885122f89c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A100 GPU detected, using flash attention if input tensor is on cuda\n",
            "\n",
            "\n",
            "Generator: 43.71M\n",
            "Discriminator: 30.74M\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-aea9fa4cc978>:4: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "  0%|          | 1/1000 [00:00<?, ?it/s]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -3.39 | MSG: -14.02 | VG: 0.00 | D: 5.51 | MSD: 15.46 | VD: 0.00 | GP: 0.00 | SSL: 14.49 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 21/1000 [00:58<46:30,  2.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -281.25 | MSG: -203.91 | VG: 0.00 | D: 276.11 | MSD: 204.89 | VD: 0.00 | GP: 27868.06 | SSL: 13.34 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 41/1000 [01:52<45:38,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -481.83 | MSG: -144.95 | VG: 0.00 | D: 485.29 | MSD: 146.91 | VD: 0.00 | GP: 27182.68 | SSL: 16.27 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 61/1000 [02:46<44:53,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -700.80 | MSG: -125.20 | VG: 0.00 | D: 703.15 | MSD: 126.34 | VD: 0.00 | GP: 29783.50 | SSL: 12.87 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 81/1000 [03:40<43:45,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1048.18 | MSG: -163.38 | VG: 0.00 | D: 1050.32 | MSD: 164.52 | VD: 0.00 | GP: 27097.93 | SSL: 11.86 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 100/1000 [04:30<38:06,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1085.39 | MSG: -155.58 | VG: 0.00 | D: 1084.97 | MSD: 156.82 | VD: 0.00 | GP: 28804.74 | SSL: 14.16 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 121/1000 [05:30<41:39,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1239.17 | MSG: -147.89 | VG: 0.00 | D: 1241.30 | MSD: 149.77 | VD: 0.00 | GP: 29105.22 | SSL: 13.67 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 141/1000 [06:24<40:50,  2.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1427.19 | MSG: -151.59 | VG: 0.00 | D: 1428.10 | MSD: 153.31 | VD: 0.00 | GP: 29749.34 | SSL: 12.67 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 161/1000 [07:18<40:47,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1509.67 | MSG: -156.79 | VG: 0.00 | D: 1513.65 | MSD: 158.81 | VD: 0.00 | GP: 29453.61 | SSL: 15.30 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 181/1000 [08:12<39:16,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1623.84 | MSG: -161.05 | VG: 0.00 | D: 1628.78 | MSD: 162.49 | VD: 0.00 | GP: 29099.44 | SSL: 12.47 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 200/1000 [09:03<34:23,  2.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1676.50 | MSG: -153.83 | VG: 0.00 | D: 1679.79 | MSD: 155.65 | VD: 0.00 | GP: 27498.29 | SSL: 11.69 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 221/1000 [10:04<37:21,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1793.17 | MSG: -155.31 | VG: 0.00 | D: 1796.67 | MSD: 156.88 | VD: 0.00 | GP: 25841.54 | SSL: 14.20 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 241/1000 [10:58<36:38,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -1911.31 | MSG: -152.58 | VG: 0.00 | D: 1914.52 | MSD: 154.20 | VD: 0.00 | GP: 27447.73 | SSL: 12.04 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 261/1000 [11:52<35:17,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2006.81 | MSG: -154.91 | VG: 0.00 | D: 2010.58 | MSD: 156.56 | VD: 0.00 | GP: 29325.69 | SSL: 13.98 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 281/1000 [12:46<34:34,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2111.53 | MSG: -155.36 | VG: 0.00 | D: 2110.55 | MSD: 156.81 | VD: 0.00 | GP: 28528.46 | SSL: 11.09 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 300/1000 [13:36<29:38,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2206.39 | MSG: -161.36 | VG: 0.00 | D: 2211.28 | MSD: 163.08 | VD: 0.00 | GP: 29366.54 | SSL: 14.39 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 321/1000 [14:37<32:15,  2.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2302.78 | MSG: -155.79 | VG: 0.00 | D: 2307.19 | MSD: 157.22 | VD: 0.00 | GP: 27709.11 | SSL: 13.59 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 341/1000 [15:32<31:24,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2426.56 | MSG: -157.76 | VG: 0.00 | D: 2427.71 | MSD: 159.29 | VD: 0.00 | GP: 29409.28 | SSL: 16.86 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 361/1000 [16:25<30:28,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2475.14 | MSG: -162.75 | VG: 0.00 | D: 2478.20 | MSD: 164.32 | VD: 0.00 | GP: 28859.73 | SSL: 14.15 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 381/1000 [17:19<29:45,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2594.19 | MSG: -157.59 | VG: 0.00 | D: 2594.54 | MSD: 159.15 | VD: 0.00 | GP: 27293.61 | SSL: 15.54 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 400/1000 [18:10<25:30,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2675.23 | MSG: -152.27 | VG: 0.00 | D: 2679.59 | MSD: 153.92 | VD: 0.00 | GP: 31326.24 | SSL: 12.14 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 421/1000 [19:11<27:43,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2733.28 | MSG: -158.94 | VG: 0.00 | D: 2734.12 | MSD: 160.54 | VD: 0.00 | GP: 28503.82 | SSL: 13.24 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 441/1000 [20:05<26:50,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: -2839.30 | MSG: -154.89 | VG: 0.00 | D: 2840.56 | MSD: 156.51 | VD: 0.00 | GP: 28207.96 | SSL: 12.96 | CL: 0.00 | MAL: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 449/1000 [20:29<25:11,  2.74s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 382.88 MiB is free. Process 51716 has 39.17 GiB memory in use. Of the allocated memory 35.77 GiB is allocated by PyTorch, and 2.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cebbe2a870e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gigagan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-d69b92cceb23>\u001b[0m in \u001b[0;36mtrain_gigagan\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Initial (Unpruned)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAINING_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model-unpruned.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# ---------------------------- Phase 2: Prune + Fine-tune ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-aea9fa4cc978>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(gan, dataloader, steps, save_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training for {steps} steps (AMP enabled)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_accum_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gigagan_pytorch/gigagan_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, steps, grad_accum_every)\u001b[0m\n\u001b[1;32m   2593\u001b[0m                 \u001b[0mvision_aided_g_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                 \u001b[0mcontrastive_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2595\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2596\u001b[0m                 \u001b[0mdl_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gigagan_pytorch/gigagan_pytorch.py\u001b[0m in \u001b[0;36mtrain_generator_step\u001b[0;34m(self, batch_size, dl_iter, grad_accum_every, calc_multiscale_loss)\u001b[0m\n\u001b[1;32m   2463\u001b[0m                     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvd_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_aided_divergence_loss_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgrad_accum_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_contrastive_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0;31m# if needs the generator contrastive loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 382.88 MiB is free. Process 51716 has 39.17 GiB memory in use. Of the allocated memory 35.77 GiB is allocated by PyTorch, and 2.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prune_and_finetune_gigagan()\n",
        "gan = setup_model()\n",
        "gan.load(os.path.join(MODEL_FOLDER, \"model-unpruned.ckpt\"))\n",
        "count_nonzero_params(gan, \"After Training\")"
      ],
      "metadata": {
        "id": "gkFBAy2kAenH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}