{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2w6Cu27eFJtI",
    "outputId": "51edf027-4e77-4b4b-d08e-505b1871faab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: huggingface_hub in ./.local/lib/python3.9/site-packages (0.30.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: validators in ./.local/lib/python3.9/site-packages (0.34.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.9/site-packages (4.51.3)\n",
      "Requirement already satisfied: fvcore in ./.local/lib/python3.9/site-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.9/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.9/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.local/lib/python3.9/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.9/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: packaging in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.9/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.local/lib/python3.9/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: yacs>=0.1.6 in ./.local/lib/python3.9/site-packages (from fvcore) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in ./.local/lib/python3.9/site-packages (from fvcore) (3.0.1)\n",
      "Requirement already satisfied: tabulate in ./.local/lib/python3.9/site-packages (from fvcore) (0.9.0)\n",
      "Requirement already satisfied: iopath>=0.1.7 in ./.local/lib/python3.9/site-packages (from fvcore) (0.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.4.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: portalocker in ./.local/lib/python3.9/site-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.9/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install required packages\n",
    "!pip install datasets huggingface_hub torch torchvision validators transformers fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GeXJcqZFL-W",
    "outputId": "36832482-ff10-4ae3-d5bf-b839773aae7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gigagan-pytorch==0.2.20 in ./.local/lib/python3.9/site-packages (0.2.20)\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (1.6.0)\n",
      "Requirement already satisfied: beartype in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (0.20.2)\n",
      "Requirement already satisfied: einops>=0.6 in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (0.8.1)\n",
      "Requirement already satisfied: ema-pytorch in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (0.7.7)\n",
      "Requirement already satisfied: kornia in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (0.8.0)\n",
      "Requirement already satisfied: numerize in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (0.12)\n",
      "Requirement already satisfied: open-clip-torch<3.0.0,>=2.0.0 in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (2.32.0)\n",
      "Requirement already satisfied: pillow in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (11.1.0)\n",
      "Requirement already satisfied: torch>=1.6 in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (0.21.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.2.20) (4.67.1)\n",
      "Requirement already satisfied: regex in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2024.11.6)\n",
      "Requirement already satisfied: ftfy in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (6.3.1)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (0.30.2)\n",
      "Requirement already satisfied: safetensors in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (0.5.3)\n",
      "Requirement already satisfied: timm in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (1.0.15)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.2.20) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.6->gigagan-pytorch==0.2.20) (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.local/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.2.20) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.2.20) (23.2)\n",
      "Requirement already satisfied: psutil in ./.local/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.2.20) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.2.20) (6.0.1)\n",
      "Requirement already satisfied: kornia_rs>=0.1.0 in ./.local/lib/python3.9/site-packages (from kornia->gigagan-pytorch==0.2.20) (0.1.8)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.9/site-packages (from huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2.32.3)\n",
      "Requirement already satisfied: wcwidth in ./.local/lib/python3.9/site-packages (from ftfy->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.9/site-packages (from jinja2->torch>=1.6->gigagan-pytorch==0.2.20) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.2.20) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "#Colab path\n",
    "#!pip install /content/gigagan_pytorch-0.3.9-py3-none-any.whl\n",
    "\n",
    "#Jupyter path\n",
    "#!pip install gigagan_pytorch-0.4.2-py3-none-any.whl\n",
    "\n",
    "!pip install gigagan-pytorch==0.2.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: future-annotations in ./.local/lib/python3.9/site-packages (1.0.0)\n",
      "Requirement already satisfied: tokenize-rt>=3 in ./.local/lib/python3.9/site-packages (from future-annotations) (6.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install future-annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ckfxbj4EFNRE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sb9855/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import libraries\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from __future__ import annotations\n",
    "from gigagan_pytorch import GigaGAN\n",
    "from huggingface_hub import login\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import validators\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import profiling tools\n",
    "import torch.profiler as profiler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table, parameter_count\n",
    "\n",
    "# Create profiling directory\n",
    "os.makedirs(\"profiling_results\", exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('gigagan_training.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('gigagan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CPrxGhLKFOpm"
   },
   "outputs": [],
   "source": [
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HCPD2KpBJcs_"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Setup image transformation\n",
    "UNCONDITIONAL = True\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "# Cell 2: Setup image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eBIaRVBSJedF"
   },
   "outputs": [],
   "source": [
    "def fetch_image(url, caption=None):\n",
    "    \"\"\"Fetch an image from a URL and apply transformations.\n",
    "    Returns just the image if unconditional, or (image, caption) if conditional.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not validators.url(url):\n",
    "            return None if UNCONDITIONAL else (None, None)\n",
    "        \n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code != 200:\n",
    "            return None if UNCONDITIONAL else (None, None)\n",
    "            \n",
    "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        if min(img.size) < 64:  # Filter out tiny images\n",
    "            return None if UNCONDITIONAL else (None, None)\n",
    "            \n",
    "        transformed_img = transform(img)\n",
    "        \n",
    "        if UNCONDITIONAL:\n",
    "            return transformed_img\n",
    "        else:\n",
    "            return transformed_img, caption\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching image: {e}\")\n",
    "        return None if UNCONDITIONAL else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9XeViUleJgdA"
   },
   "outputs": [],
   "source": [
    "def build_dataset(num_samples=1000):\n",
    "    \"\"\"Build dataset with progress tracking for either conditional or unconditional GAN\"\"\"\n",
    "    logger.info(f\"Building {'unconditional' if UNCONDITIONAL else 'conditional'} dataset with {num_samples} samples...\")\n",
    "\n",
    "    dataset = load_dataset(\"phiyodr/coco2017\", split=\"train\", streaming=True)\n",
    "    stream_iter = iter(dataset)\n",
    "    \n",
    "    # Will hold either just images or (image, caption) pairs depending on UNCONDITIONAL flag\n",
    "    samples = []\n",
    "\n",
    "    # Start timing dataset creation\n",
    "    start_time = time.time()\n",
    "\n",
    "    while len(samples) < num_samples:\n",
    "        if len(samples) % 100 == 0:\n",
    "            logger.info(f\"Collected {len(samples)}/{num_samples} samples...\")\n",
    "\n",
    "        try:\n",
    "            sample = next(stream_iter)\n",
    "            url = sample.get(\"coco_url\")\n",
    "\n",
    "            # Extract caption (only needed if conditional)\n",
    "            caption = None\n",
    "            if not UNCONDITIONAL:\n",
    "                if 'captions' in sample and isinstance(sample['captions'], list) and len(sample['captions']) > 0:\n",
    "                    caption = sample['captions'][0]\n",
    "                elif 'caption' in sample:\n",
    "                    caption = sample['caption']\n",
    "                    if isinstance(caption, list) and len(caption) > 0:\n",
    "                        caption = caption[0]\n",
    "                else:\n",
    "                    caption = \"A photo\"\n",
    "\n",
    "            # Fetch image (and caption if conditional)\n",
    "            result = fetch_image(url, caption)\n",
    "            \n",
    "            if result is not None:\n",
    "                samples.append(result)\n",
    "                \n",
    "        except StopIteration:\n",
    "            logger.warning(\"Dataset exhausted\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sample: {e}\")\n",
    "            continue\n",
    "\n",
    "    dataset_time = time.time() - start_time\n",
    "    logger.info(f\"Dataset built in {dataset_time:.2f}s with {len(samples)} samples\")\n",
    "\n",
    "    # Save dataset statistics\n",
    "    dataset_stats = {\n",
    "        \"mode\": \"unconditional\" if UNCONDITIONAL else \"conditional\",\n",
    "        \"num_samples\": len(samples),\n",
    "        \"build_time_seconds\": dataset_time,\n",
    "        \"avg_time_per_sample\": dataset_time / len(samples) if samples else 0\n",
    "    }\n",
    "\n",
    "    with open(\"profiling_results/dataset_stats.json\", \"w\") as f:\n",
    "        json.dump(dataset_stats, f, indent=2)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zgX5yi2TJjac"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        \"\"\"Initialize dataset with samples\n",
    "        \n",
    "        Args:\n",
    "            samples: Either list of image tensors (unconditional) or list of (image, caption) pairs (conditional)\n",
    "        \"\"\"\n",
    "        self.samples = samples\n",
    "        self.unconditional = UNCONDITIONAL\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.unconditional:\n",
    "            return self.samples[idx]  # Just return the image tensor\n",
    "        else:\n",
    "            img, caption = self.samples[idx]\n",
    "            return img, caption  # Return image and caption pair\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function that handles both conditional and unconditional batches\"\"\"\n",
    "    if UNCONDITIONAL:\n",
    "        # For unconditional, batch is just a list of image tensors\n",
    "        return torch.stack(batch)\n",
    "    else:\n",
    "        # For conditional, batch is a list of (image, caption) tuples\n",
    "        images = []\n",
    "        captions = []\n",
    "\n",
    "        for img, caption in batch:\n",
    "            images.append(img)\n",
    "            captions.append(caption)\n",
    "\n",
    "        images = torch.stack(images)\n",
    "        return images, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qn82P0vqJmbN"
   },
   "outputs": [],
   "source": [
    "# Cell 8: Dataloader profiling function\n",
    "def profile_dataloader(dataloader, num_batches=10):\n",
    "    \"\"\"Profile dataloader performance\"\"\"\n",
    "    logger.info(f\"Profiling dataloader for {num_batches} batches...\")\n",
    "\n",
    "    batch_times = []\n",
    "    batch_memory = []\n",
    "\n",
    "    # Reset memory stats\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
    "\n",
    "    # Time batches\n",
    "    for i, (images, captions) in enumerate(dataloader):\n",
    "        if i == 0:\n",
    "            # First batch may include initialization overhead\n",
    "            batch_start = time.time()\n",
    "            continue\n",
    "\n",
    "        batch_end = time.time()\n",
    "        batch_time = batch_end - batch_start\n",
    "        batch_times.append(batch_time)\n",
    "\n",
    "        # Track memory\n",
    "        current_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
    "        batch_memory.append(current_memory)\n",
    "\n",
    "        logger.info(f\"Batch {i}: loaded in {batch_time:.4f}s, memory: {current_memory:.2f} MB\")\n",
    "\n",
    "        batch_start = time.time()\n",
    "\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "    # Calculate stats\n",
    "    avg_batch_time = sum(batch_times) / len(batch_times) if batch_times else 0\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024 * 1024)  # MB\n",
    "\n",
    "    # Record results\n",
    "    dataloader_stats = {\n",
    "        \"avg_batch_time_seconds\": avg_batch_time,\n",
    "        \"batches_per_second\": 1 / avg_batch_time if avg_batch_time > 0 else 0,\n",
    "        \"starting_memory_mb\": start_memory,\n",
    "        \"peak_memory_mb\": peak_memory,\n",
    "        \"memory_increase_mb\": peak_memory - start_memory\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Dataloader avg time: {avg_batch_time:.4f}s per batch\")\n",
    "    logger.info(f\"Dataloader peak memory: {peak_memory:.2f} MB\")\n",
    "\n",
    "    with open(\"profiling_results/dataloader_stats.json\", \"w\") as f:\n",
    "        json.dump(dataloader_stats, f, indent=2)\n",
    "\n",
    "    return dataloader_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "B7qLNejjJpXJ"
   },
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    \"\"\"Set up GigaGAN model with the new configuration\"\"\"\n",
    "    logger.info(f\"Setting up {'unconditional' if UNCONDITIONAL else 'conditional'} GigaGAN model...\")\n",
    "\n",
    "    # Create the model with updated configuration\n",
    "    '''\n",
    "    gan = GigaGAN(\n",
    "        generator=dict(\n",
    "            dim_capacity=16,\n",
    "            style_network=dict(\n",
    "                dim=128,\n",
    "                depth=4\n",
    "            ),\n",
    "            image_size=IMAGE_SIZE,\n",
    "            dim_max=512,\n",
    "            num_skip_layers_excite=4,\n",
    "            unconditional=UNCONDITIONAL\n",
    "        ),\n",
    "        discriminator=dict(\n",
    "            dim_capacity=32,\n",
    "            dim_max=512,\n",
    "            image_size=IMAGE_SIZE,\n",
    "            num_skip_layers_excite=4,\n",
    "            unconditional=UNCONDITIONAL\n",
    "        ),\n",
    "        learning_rate = 1e-6,\n",
    "        accelerate_kwargs = {'gradient_accumulation_steps': 8},\n",
    "        diff_augment=dict(\n",
    "        prob=0.5,\n",
    "        horizontal_flip=True,\n",
    "        horizontal_flip_prob=0.5\n",
    "        ),\n",
    "        apply_gradient_penalty_every=16,  # Less frequent gradient penalty\n",
    "        multiscale_divergence_loss_weight=0.15,  # Increased from default\n",
    "        discr_aux_recon_loss_weight=0.8,\n",
    "        amp=True  # Enable mixed precision\n",
    "    ).cuda()\n",
    "\n",
    "    gan.load('gigagan-models/model-5.ckpt')\n",
    "    '''\n",
    "    gan = GigaGAN(\n",
    "        train_upsampler = True,\n",
    "        generator = dict(\n",
    "            dim = 32,                  # Use dim instead of dim_capacity for UnetUpsampler\n",
    "            style_network = dict(\n",
    "                dim = 64,\n",
    "                depth = 4\n",
    "            ),\n",
    "            image_size = IMAGE_SIZE,          # Output resolution\n",
    "            input_image_size = 64,     # Input resolution to upsample from\n",
    "            unconditional = True\n",
    "        ),\n",
    "        discriminator = dict(\n",
    "            dim_capacity = 16,\n",
    "            dim_max = 512,\n",
    "            image_size = IMAGE_SIZE,          # Match with generator output size\n",
    "            multiscale_input_resolutions = (128,),  # Intermediate resolution\n",
    "            num_skip_layers_excite = 4,\n",
    "            unconditional = True\n",
    "        ),\n",
    "        learning_rate=1e-5,\n",
    "        model_folder='./gigagan-modified-upsampler-models',\n",
    "        results_folder='./gigagan-modified-upsampler-results',\n",
    "        amp = True\n",
    "    ).cuda()\n",
    "    gan.load('gigagan-modified-upsampler-models/model-11.ckpt')\n",
    "\n",
    "    # Profile model architecture\n",
    "    gen_params = sum(p.numel() for p in gan.unwrapped_G.parameters())\n",
    "    disc_params = sum(p.numel() for p in gan.unwrapped_D.parameters())\n",
    "    total_params = sum(p.numel() for p in gan.parameters())\n",
    "    trainable_params = sum(p.numel() for p in gan.parameters() if p.requires_grad)\n",
    "\n",
    "    # Estimate model size\n",
    "    param_size_bytes = sum(p.numel() * p.element_size() for p in gan.parameters())\n",
    "    buffer_size_bytes = sum(b.numel() * b.element_size() for b in gan.buffers())\n",
    "    model_size_mb = (param_size_bytes + buffer_size_bytes) / (1024 * 1024)\n",
    "\n",
    "    # Record architecture stats\n",
    "    architecture_stats = {\n",
    "        \"mode\": \"unconditional\" if UNCONDITIONAL else \"conditional\",\n",
    "        \"generator_parameters\": gen_params,\n",
    "        \"discriminator_parameters\": disc_params,\n",
    "        \"total_parameters\": total_params,\n",
    "        \"trainable_parameters\": trainable_params,\n",
    "        \"model_size_mb\": model_size_mb,\n",
    "        \"generator_percentage\": gen_params / total_params * 100,\n",
    "        \"discriminator_percentage\": disc_params / total_params * 100\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Model architecture: {gen_params:,} generator params, {disc_params:,} discriminator params\")\n",
    "    logger.info(f\"Total parameters: {total_params:,} ({trainable_params:,} trainable)\")\n",
    "    logger.info(f\"Model size: {model_size_mb:.2f} MB\")\n",
    "\n",
    "    with open(\"profiling_results/model_architecture.json\", \"w\") as f:\n",
    "        json.dump(architecture_stats, f, indent=2)\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(gan, dataloader, steps=100, grad_accum_every=8):\n",
    "    \"\"\"Train the GigaGAN model\"\"\"\n",
    "    logger.info(f\"Training {'unconditional' if UNCONDITIONAL else 'conditional'} GigaGAN for {steps} steps...\")\n",
    "    \n",
    "    # Set dataloader\n",
    "    gan.set_dataloader(dataloader)\n",
    "    \n",
    "    # Train for specified steps\n",
    "    gan(steps=steps, grad_accum_every=grad_accum_every)\n",
    "    \n",
    "    logger.info(f\"Training completed for {steps} steps\")\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(gan, batch_size=4, captions=None):\n",
    "    \"\"\"Generate images using the trained model\n",
    "    \n",
    "    For unconditional GAN, only batch_size is needed\n",
    "    For conditional GAN, both batch_size and captions are needed\n",
    "    \"\"\"\n",
    "    if UNCONDITIONAL:\n",
    "        logger.info(f\"Generating {batch_size} images unconditionally\")\n",
    "        with torch.no_grad():\n",
    "            input_size = gan.unwrapped_G.input_image_size\n",
    "            lowres = torch.randn(1, 3, input_size, input_size).cuda()\n",
    "            images = gan.generate(lowres_image=lowres)\n",
    "    else:\n",
    "        if captions is None or len(captions) < batch_size:\n",
    "            logger.error(\"Captions must be provided for conditional generation\")\n",
    "            return None\n",
    "            \n",
    "        logger.info(f\"Generating {batch_size} images with captions\")\n",
    "        with torch.no_grad():\n",
    "            images = gan.generate(batch_size=batch_size, texts=captions[:batch_size])\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images, save_dir=\"gigagan-256-results\"):\n",
    "    \"\"\"Save generated images with proper denormalization\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Create a transform to convert tensor to PIL image\n",
    "    to_pil = transforms.ToPILImage()\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        # Properly denormalize from [-1, 1] to [0, 1]\n",
    "        img = torch.nan_to_num(img, nan=0.0)\n",
    "        img = (img.clamp(-1, 1) * 0.5 + 0.5)\n",
    "\n",
    "        # Convert to PIL and save\n",
    "        pil_img = to_pil(img.cpu())\n",
    "        filename = f\"generated_image_{i}.png\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "        logger.info(f\"Saving image to {filepath}\")\n",
    "        pil_img.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gigagan_workflow(unconditional=True, num_samples=1000, training_steps=100):\n",
    "    \"\"\"Run the complete GigaGAN workflow with the specified mode\"\"\"\n",
    "    global UNCONDITIONAL\n",
    "    UNCONDITIONAL = unconditional\n",
    "    \n",
    "    logger.info(f\"Starting GigaGAN workflow in {'unconditional' if UNCONDITIONAL else 'conditional'} mode\")\n",
    "    \n",
    "    # 1. Build dataset\n",
    "    samples = build_dataset(num_samples=num_samples)\n",
    "    \n",
    "    # 2. Create dataset and dataloader\n",
    "    dataset = ImageDataset(samples)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4,  # Use small batch size due to memory constraints\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # 3. Setup model\n",
    "    gan = setup_model()\n",
    "    \n",
    "    \n",
    "    # 5. Train model\n",
    "    gan = train_model(gan, dataloader, steps=training_steps, grad_accum_every=8)\n",
    "\n",
    "    \n",
    "    # 7. Generate and save images\n",
    "    if UNCONDITIONAL:\n",
    "        images = generate_images(gan, batch_size=4)\n",
    "    else:\n",
    "        # Sample captions for conditional generation\n",
    "        test_captions = [\n",
    "            \"A dog running in a park\",\n",
    "            \"A beautiful sunset over the ocean\",\n",
    "            \"A cat sleeping on a sofa\",\n",
    "            \"A mountain landscape with snow\"\n",
    "        ]\n",
    "        images = generate_images(gan, batch_size=4, captions=test_captions)\n",
    "    \n",
    "    if images is not None:\n",
    "        save_images(images)\n",
    "    \n",
    "    logger.info(\"GigaGAN workflow completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gigagan:Starting GigaGAN workflow in unconditional mode\n",
      "INFO:gigagan:Building unconditional dataset with 2000 samples...\n",
      "INFO:gigagan:Collected 0/2000 samples...\n",
      "INFO:gigagan:Collected 100/2000 samples...\n",
      "INFO:gigagan:Collected 200/2000 samples...\n",
      "INFO:gigagan:Collected 300/2000 samples...\n",
      "INFO:gigagan:Collected 400/2000 samples...\n",
      "INFO:gigagan:Collected 500/2000 samples...\n",
      "INFO:gigagan:Collected 600/2000 samples...\n",
      "INFO:gigagan:Collected 700/2000 samples...\n",
      "INFO:gigagan:Collected 800/2000 samples...\n",
      "INFO:gigagan:Collected 900/2000 samples...\n",
      "INFO:gigagan:Collected 1000/2000 samples...\n",
      "INFO:gigagan:Collected 1100/2000 samples...\n",
      "INFO:gigagan:Collected 1200/2000 samples...\n",
      "INFO:gigagan:Collected 1300/2000 samples...\n",
      "INFO:gigagan:Collected 1400/2000 samples...\n",
      "INFO:gigagan:Collected 1500/2000 samples...\n",
      "INFO:gigagan:Collected 1600/2000 samples...\n",
      "INFO:gigagan:Collected 1700/2000 samples...\n",
      "INFO:gigagan:Collected 1800/2000 samples...\n",
      "INFO:gigagan:Collected 1900/2000 samples...\n",
      "INFO:gigagan:Dataset built in 468.40s with 2000 samples\n",
      "INFO:gigagan:Setting up unconditional GigaGAN model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A100 GPU detected, using flash attention if input tensor is on cuda\n",
      "\n",
      "\n",
      "Generator: 43.71M\n",
      "Discriminator: 30.74M\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gigagan:Model architecture: 43,712,753 generator params, 30,737,601 discriminator params\n",
      "INFO:gigagan:Total parameters: 118,163,107 (74,450,354 trainable)\n",
      "INFO:gigagan:Model size: 450.76 MB\n",
      "INFO:gigagan:Training unconditional GigaGAN for 5000 steps...\n",
      "11000it [00:00, ?it/s]/share/apps/pyenv/py3.9/lib/python3.9/contextlib.py:87: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.47 | MSG: -0.01 | VG: 0.00 | D: 1.90 | MSD: 2.00 | VD: 0.00 | GP: 0.24 | SSL: 0.08 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11021it [01:19,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.73 | MSG: -0.00 | VG: 0.00 | D: 0.98 | MSD: 2.00 | VD: 0.00 | GP: 0.29 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11041it [02:15,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.09 | MSG: 0.00 | VG: 0.00 | D: 1.16 | MSD: 2.00 | VD: 0.00 | GP: 0.18 | SSL: 0.08 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11061it [03:11,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.80 | MSG: -0.01 | VG: 0.00 | D: 1.13 | MSD: 2.00 | VD: 0.00 | GP: 0.17 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11081it [04:07,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.94 | MSG: -0.00 | VG: 0.00 | D: 0.84 | MSD: 2.00 | VD: 0.00 | GP: 0.18 | SSL: 0.09 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11101it [05:03,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.39 | MSG: -0.00 | VG: 0.00 | D: 0.93 | MSD: 2.00 | VD: 0.00 | GP: 0.20 | SSL: 0.07 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11121it [05:59,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.82 | MSG: -0.02 | VG: 0.00 | D: 1.42 | MSD: 2.00 | VD: 0.00 | GP: 0.21 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11141it [06:54,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 2.00 | MSG: -0.01 | VG: 0.00 | D: 0.72 | MSD: 2.00 | VD: 0.00 | GP: 0.18 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11144it [07:01,  2.60s/it]"
     ]
    }
   ],
   "source": [
    "# For unconditional training:\n",
    "run_gigagan_workflow(unconditional=True, num_samples=2000, training_steps=5000)\n",
    "\n",
    "# For conditional training:\n",
    "# run_gigagan_workflow(unconditional=False, num_samples=2000, training_steps=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "051984134e66460584306a7136f18fb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2f42a2818ee4f4da258e16f33b75f25",
       "IPY_MODEL_1d09d81fba274e0b937a57688bdc5d49",
       "IPY_MODEL_fbdf6e208e6647e79852bfdbe0e58e18"
      ],
      "layout": "IPY_MODEL_27d1f1aeec0b4b3abb6dc6303e2cc937"
     }
    },
    "0ea7f708e10b42d2a1c8327d80c49d86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1007ffa7a42341af8d2aa5d0411d7573": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "106c9aeb02904aca894b391f930fb915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7446b9c51c9a4ab481e80f05bfa9cf8c",
      "placeholder": "​",
      "style": "IPY_MODEL_350bc3d681e44cba8c5b8ba0306c9ab5",
      "value": " 605M/605M [00:08&lt;00:00, 69.2MB/s]"
     }
    },
    "166196a8780949588af843711d61990b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d09d81fba274e0b937a57688bdc5d49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ea7f708e10b42d2a1c8327d80c49d86",
      "max": 2705,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_166196a8780949588af843711d61990b",
      "value": 2705
     }
    },
    "27d1f1aeec0b4b3abb6dc6303e2cc937": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c0d9c3451714848903c995591cec4f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fca778cfd204fc4ab4dc5889f5cd7ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bff8228516cc44959f11f3869643ad89",
      "placeholder": "​",
      "style": "IPY_MODEL_2c0d9c3451714848903c995591cec4f3",
      "value": "open_clip_model.safetensors: 100%"
     }
    },
    "350bc3d681e44cba8c5b8ba0306c9ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "617dc048584e49ab9a47c86a2ac74336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7446b9c51c9a4ab481e80f05bfa9cf8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86e7091f6af144c29d8528798cd7d8de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb69eab07e294831a1d5e8dfd46de5f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be89926d107d417f889a3a1d012fefdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bff8228516cc44959f11f3869643ad89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f42a2818ee4f4da258e16f33b75f25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd3ded79b20d47dcb96e62a76f96935e",
      "placeholder": "​",
      "style": "IPY_MODEL_617dc048584e49ab9a47c86a2ac74336",
      "value": "README.md: 100%"
     }
    },
    "c8c7f3cb584e41379c392cca00fe0401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3ded79b20d47dcb96e62a76f96935e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d24c48a6af3049318e5ed8438c99d0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2fca778cfd204fc4ab4dc5889f5cd7ef",
       "IPY_MODEL_d9104cc68a8542daab09fcf5a5f446c5",
       "IPY_MODEL_106c9aeb02904aca894b391f930fb915"
      ],
      "layout": "IPY_MODEL_86e7091f6af144c29d8528798cd7d8de"
     }
    },
    "d9104cc68a8542daab09fcf5a5f446c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1007ffa7a42341af8d2aa5d0411d7573",
      "max": 605143284,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be89926d107d417f889a3a1d012fefdb",
      "value": 605143284
     }
    },
    "fbdf6e208e6647e79852bfdbe0e58e18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb69eab07e294831a1d5e8dfd46de5f2",
      "placeholder": "​",
      "style": "IPY_MODEL_c8c7f3cb584e41379c392cca00fe0401",
      "value": " 2.71k/2.71k [00:00&lt;00:00, 102kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
