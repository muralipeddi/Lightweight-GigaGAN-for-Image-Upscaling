{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2w6Cu27eFJtI",
    "outputId": "51edf027-4e77-4b4b-d08e-505b1871faab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: huggingface_hub in ./.local/lib/python3.9/site-packages (0.30.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: validators in ./.local/lib/python3.9/site-packages (0.34.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.9/site-packages (4.51.3)\n",
      "Requirement already satisfied: fvcore in ./.local/lib/python3.9/site-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.9/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.9/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.local/lib/python3.9/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.9/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: packaging in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.9/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.local/lib/python3.9/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.9/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.9/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: yacs>=0.1.6 in ./.local/lib/python3.9/site-packages (from fvcore) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in ./.local/lib/python3.9/site-packages (from fvcore) (3.0.1)\n",
      "Requirement already satisfied: tabulate in ./.local/lib/python3.9/site-packages (from fvcore) (0.9.0)\n",
      "Requirement already satisfied: iopath>=0.1.7 in ./.local/lib/python3.9/site-packages (from fvcore) (0.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.4.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: portalocker in ./.local/lib/python3.9/site-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.9/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install required packages\n",
    "!pip install datasets huggingface_hub torch torchvision validators transformers fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GeXJcqZFL-W",
    "outputId": "36832482-ff10-4ae3-d5bf-b839773aae7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing ./gigagan_pytorch-0.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (1.6.0)\n",
      "Requirement already satisfied: beartype in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (0.20.2)\n",
      "Requirement already satisfied: einops>=0.6 in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (0.8.1)\n",
      "Requirement already satisfied: ema-pytorch in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (0.7.7)\n",
      "Requirement already satisfied: kornia in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (0.8.0)\n",
      "Requirement already satisfied: numerize in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (0.12)\n",
      "Requirement already satisfied: open-clip-torch<3.0.0,>=2.0.0 in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (2.32.0)\n",
      "Requirement already satisfied: pillow in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (11.1.0)\n",
      "Requirement already satisfied: torch>=1.6 in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (0.21.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.9/site-packages (from gigagan-pytorch==0.4.0) (4.67.1)\n",
      "Requirement already satisfied: regex in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (2024.11.6)\n",
      "Requirement already satisfied: ftfy in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (6.3.1)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (0.30.2)\n",
      "Requirement already satisfied: safetensors in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (0.5.3)\n",
      "Requirement already satisfied: timm in ./.local/lib/python3.9/site-packages (from open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (1.0.15)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch>=1.6->gigagan-pytorch==0.4.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.6->gigagan-pytorch==0.4.0) (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.local/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.4.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.4.0) (23.2)\n",
      "Requirement already satisfied: psutil in ./.local/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.4.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from accelerate->gigagan-pytorch==0.4.0) (6.0.1)\n",
      "Requirement already satisfied: kornia_rs>=0.1.0 in ./.local/lib/python3.9/site-packages (from kornia->gigagan-pytorch==0.4.0) (0.1.8)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.9/site-packages (from huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (2.32.3)\n",
      "Requirement already satisfied: wcwidth in ./.local/lib/python3.9/site-packages (from ftfy->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.9/site-packages (from jinja2->torch>=1.6->gigagan-pytorch==0.4.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/pyenv/py3.9/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.9/site-packages (from requests->huggingface-hub->open-clip-torch<3.0.0,>=2.0.0->gigagan-pytorch==0.4.0) (2025.1.31)\n",
      "gigagan-pytorch is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "#Colab path\n",
    "#!pip install /content/gigagan_pytorch-0.3.9-py3-none-any.whl\n",
    "\n",
    "#Jupyter path\n",
    "!pip install gigagan_pytorch-0.4.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: future-annotations in ./.local/lib/python3.9/site-packages (1.0.0)\n",
      "Requirement already satisfied: tokenize-rt>=3 in ./.local/lib/python3.9/site-packages (from future-annotations) (6.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install future-annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Ckfxbj4EFNRE"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Import libraries\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from __future__ import annotations\n",
    "from gigagan_pytorch import GigaGAN\n",
    "from huggingface_hub import login\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import validators\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import profiling tools\n",
    "import torch.profiler as profiler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table, parameter_count\n",
    "\n",
    "# Create profiling directory\n",
    "os.makedirs(\"profiling_results\", exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('gigagan_training.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('gigagan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CPrxGhLKFOpm"
   },
   "outputs": [],
   "source": [
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HCPD2KpBJcs_"
   },
   "outputs": [],
   "source": [
    "UNCONDITIONAL = True\n",
    "IMAGE_SIZE = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eBIaRVBSJedF"
   },
   "outputs": [],
   "source": [
    "def fetch_image(url, caption=None):\n",
    "    \"\"\"Fetch an image from a URL and apply transformations.\n",
    "    Returns just the image if unconditional, or (image, caption) if conditional.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not validators.url(url):\n",
    "            return None if UNCONDITIONAL else (None, None)\n",
    "        \n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code != 200:\n",
    "            return None if UNCONDITIONAL else (None, None)\n",
    "            \n",
    "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        if min(img.size) < 64:  # Filter out tiny images\n",
    "            return None if UNCONDITIONAL else (None, None)\n",
    "            \n",
    "        transformed_img = transform(img)\n",
    "        \n",
    "        if UNCONDITIONAL:\n",
    "            return transformed_img\n",
    "        else:\n",
    "            return transformed_img, caption\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching image: {e}\")\n",
    "        return None if UNCONDITIONAL else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9XeViUleJgdA"
   },
   "outputs": [],
   "source": [
    "def build_dataset(num_samples=1000):\n",
    "    logger.info(f\"Building {'unconditional' if UNCONDITIONAL else 'conditional'} dataset with {num_samples} samples...\")\n",
    "\n",
    "    dataset = load_dataset(\"phiyodr/coco2017\", split=\"train\", streaming=True)\n",
    "    stream_iter = iter(dataset)\n",
    "    \n",
    "    # Will hold either just images or (image, caption) pairs depending on UNCONDITIONAL flag\n",
    "    samples = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while len(samples) < num_samples:\n",
    "        if len(samples) % 100 == 0:\n",
    "            logger.info(f\"Collected {len(samples)}/{num_samples} samples...\")\n",
    "\n",
    "        try:\n",
    "            sample = next(stream_iter)\n",
    "            url = sample.get(\"coco_url\")\n",
    "\n",
    "            caption = None\n",
    "            if not UNCONDITIONAL:\n",
    "                if 'captions' in sample and isinstance(sample['captions'], list) and len(sample['captions']) > 0:\n",
    "                    caption = sample['captions'][0]\n",
    "                elif 'caption' in sample:\n",
    "                    caption = sample['caption']\n",
    "                    if isinstance(caption, list) and len(caption) > 0:\n",
    "                        caption = caption[0]\n",
    "                else:\n",
    "                    caption = \"A photo\"\n",
    "\n",
    "            result = fetch_image(url, caption)\n",
    "            \n",
    "            if result is not None:\n",
    "                samples.append(result)\n",
    "                \n",
    "        except StopIteration:\n",
    "            logger.warning(\"Dataset exhausted\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sample: {e}\")\n",
    "            continue\n",
    "\n",
    "    dataset_time = time.time() - start_time\n",
    "    logger.info(f\"Dataset built in {dataset_time:.2f}s with {len(samples)} samples\")\n",
    "\n",
    "    dataset_stats = {\n",
    "        \"mode\": \"unconditional\" if UNCONDITIONAL else \"conditional\",\n",
    "        \"num_samples\": len(samples),\n",
    "        \"build_time_seconds\": dataset_time,\n",
    "        \"avg_time_per_sample\": dataset_time / len(samples) if samples else 0\n",
    "    }\n",
    "\n",
    "    with open(\"profiling_results/dataset_stats.json\", \"w\") as f:\n",
    "        json.dump(dataset_stats, f, indent=2)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zgX5yi2TJjac"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        \"\"\"Initialize dataset with samples\n",
    "        \n",
    "        Args:\n",
    "            samples: Either list of image tensors (unconditional) or list of (image, caption) pairs (conditional)\n",
    "        \"\"\"\n",
    "        self.samples = samples\n",
    "        self.unconditional = UNCONDITIONAL\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.unconditional:\n",
    "            return self.samples[idx]\n",
    "        else:\n",
    "            img, caption = self.samples[idx]\n",
    "            return img, caption \n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function that handles both conditional and unconditional batches\"\"\"\n",
    "    if UNCONDITIONAL:\n",
    "        return torch.stack(batch)\n",
    "    else:\n",
    "        images = []\n",
    "        captions = []\n",
    "\n",
    "        for img, caption in batch:\n",
    "            images.append(img)\n",
    "            captions.append(caption)\n",
    "\n",
    "        images = torch.stack(images)\n",
    "        return images, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qn82P0vqJmbN"
   },
   "outputs": [],
   "source": [
    "#Dataloader profiling function\n",
    "def profile_dataloader(dataloader, num_batches=10):\n",
    "    \"\"\"Profile dataloader performance\"\"\"\n",
    "    logger.info(f\"Profiling dataloader for {num_batches} batches...\")\n",
    "\n",
    "    batch_times = []\n",
    "    batch_memory = []\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
    "\n",
    "    # Time batches\n",
    "    for i, (images, captions) in enumerate(dataloader):\n",
    "        if i == 0:\n",
    "            # First batch may include initialization overhead\n",
    "            batch_start = time.time()\n",
    "            continue\n",
    "\n",
    "        batch_end = time.time()\n",
    "        batch_time = batch_end - batch_start\n",
    "        batch_times.append(batch_time)\n",
    "\n",
    "        current_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
    "        batch_memory.append(current_memory)\n",
    "\n",
    "        logger.info(f\"Batch {i}: loaded in {batch_time:.4f}s, memory: {current_memory:.2f} MB\")\n",
    "\n",
    "        batch_start = time.time()\n",
    "\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "    avg_batch_time = sum(batch_times) / len(batch_times) if batch_times else 0\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024 * 1024)  # MB\n",
    "\n",
    "    dataloader_stats = {\n",
    "        \"avg_batch_time_seconds\": avg_batch_time,\n",
    "        \"batches_per_second\": 1 / avg_batch_time if avg_batch_time > 0 else 0,\n",
    "        \"starting_memory_mb\": start_memory,\n",
    "        \"peak_memory_mb\": peak_memory,\n",
    "        \"memory_increase_mb\": peak_memory - start_memory\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Dataloader avg time: {avg_batch_time:.4f}s per batch\")\n",
    "    logger.info(f\"Dataloader peak memory: {peak_memory:.2f} MB\")\n",
    "\n",
    "    with open(\"profiling_results/dataloader_stats.json\", \"w\") as f:\n",
    "        json.dump(dataloader_stats, f, indent=2)\n",
    "\n",
    "    return dataloader_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "B7qLNejjJpXJ"
   },
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    logger.info(f\"Setting up {'unconditional' if UNCONDITIONAL else 'conditional'} GigaGAN model...\")\n",
    "\n",
    "    gan = GigaGAN(\n",
    "        generator=dict(\n",
    "            dim_capacity=8,\n",
    "            style_network=dict(\n",
    "                dim=64,\n",
    "                depth=4\n",
    "            ),\n",
    "            image_size=IMAGE_SIZE,\n",
    "            dim_max=512,\n",
    "            num_skip_layers_excite=4,\n",
    "            unconditional=UNCONDITIONAL\n",
    "        ),\n",
    "        discriminator=dict(\n",
    "            dim_capacity=16,\n",
    "            dim_max=512,\n",
    "            image_size=IMAGE_SIZE,\n",
    "            num_skip_layers_excite=4,\n",
    "            unconditional=UNCONDITIONAL\n",
    "        ),\n",
    "        learning_rate = 1e-5,\n",
    "        accelerate_kwargs = {'gradient_accumulation_steps': 8},\n",
    "        amp=True  # Enable mixed precision\n",
    "    ).cuda()\n",
    "\n",
    "    # Profile model architecture\n",
    "    gen_params = sum(p.numel() for p in gan.unwrapped_G.parameters())\n",
    "    disc_params = sum(p.numel() for p in gan.unwrapped_D.parameters())\n",
    "    total_params = sum(p.numel() for p in gan.parameters())\n",
    "    trainable_params = sum(p.numel() for p in gan.parameters() if p.requires_grad)\n",
    "\n",
    "    param_size_bytes = sum(p.numel() * p.element_size() for p in gan.parameters())\n",
    "    buffer_size_bytes = sum(b.numel() * b.element_size() for b in gan.buffers())\n",
    "    model_size_mb = (param_size_bytes + buffer_size_bytes) / (1024 * 1024)\n",
    "\n",
    "    # Record architecture stats\n",
    "    architecture_stats = {\n",
    "        \"mode\": \"unconditional\" if UNCONDITIONAL else \"conditional\",\n",
    "        \"generator_parameters\": gen_params,\n",
    "        \"discriminator_parameters\": disc_params,\n",
    "        \"total_parameters\": total_params,\n",
    "        \"trainable_parameters\": trainable_params,\n",
    "        \"model_size_mb\": model_size_mb,\n",
    "        \"generator_percentage\": gen_params / total_params * 100,\n",
    "        \"discriminator_percentage\": disc_params / total_params * 100\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Model architecture: {gen_params:,} generator params, {disc_params:,} discriminator params\")\n",
    "    logger.info(f\"Total parameters: {total_params:,} ({trainable_params:,} trainable)\")\n",
    "    logger.info(f\"Model size: {model_size_mb:.2f} MB\")\n",
    "\n",
    "    with open(\"profiling_results/model_architecture.json\", \"w\") as f:\n",
    "        json.dump(architecture_stats, f, indent=2)\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(gan, dataloader, steps=100, grad_accum_every=4):\n",
    "    logger.info(f\"Training {'unconditional' if UNCONDITIONAL else 'conditional'} GigaGAN for {steps} steps...\")\n",
    "    \n",
    "    gan.set_dataloader(dataloader)\n",
    "    \n",
    "    gan(steps=steps, grad_accum_every=grad_accum_every)\n",
    "    \n",
    "    logger.info(f\"Training completed for {steps} steps\")\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(gan, batch_size=4, captions=None):\n",
    "    if UNCONDITIONAL:\n",
    "        logger.info(f\"Generating {batch_size} images unconditionally\")\n",
    "        with torch.no_grad():\n",
    "            images = gan.generate(batch_size=batch_size)\n",
    "    else:\n",
    "        if captions is None or len(captions) < batch_size:\n",
    "            logger.error(\"Captions must be provided for conditional generation\")\n",
    "            return None\n",
    "            \n",
    "        logger.info(f\"Generating {batch_size} images with captions\")\n",
    "        with torch.no_grad():\n",
    "            images = gan.generate(batch_size=batch_size, texts=captions[:batch_size])\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images, save_dir=\"gigagan-results\"):\n",
    "    \"\"\"Save generated images with proper denormalization\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Create a transform to convert tensor to PIL image\n",
    "    to_pil = transforms.ToPILImage()\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        # Properly denormalize from [-1, 1] to [0, 1]\n",
    "        img = torch.nan_to_num(img, nan=0.0)\n",
    "        img = (img.clamp(-1, 1) * 0.5 + 0.5)\n",
    "\n",
    "        # Convert to PIL and save\n",
    "        pil_img = to_pil(img.cpu())\n",
    "        filename = f\"generated_image_{i}.png\"\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "        logger.info(f\"Saving image to {filepath}\")\n",
    "        pil_img.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gigagan_workflow(unconditional=True, num_samples=1000, training_steps=100):\n",
    "    \"\"\"Run the complete GigaGAN workflow with the specified mode\"\"\"\n",
    "    global UNCONDITIONAL\n",
    "    UNCONDITIONAL = unconditional\n",
    "    \n",
    "    logger.info(f\"Starting GigaGAN workflow in {'unconditional' if UNCONDITIONAL else 'conditional'} mode\")\n",
    "    \n",
    "    # 1. Build dataset\n",
    "    samples = build_dataset(num_samples=num_samples)\n",
    "    \n",
    "    # 2. Create dataset and dataloader\n",
    "    dataset = ImageDataset(samples)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    gan = setup_model()\n",
    "    \n",
    "    gan = train_model(gan, dataloader, steps=training_steps, grad_accum_every=8)\n",
    "    \n",
    "    if UNCONDITIONAL:\n",
    "        images = generate_images(gan, batch_size=4)\n",
    "    else:\n",
    "        test_captions = [\n",
    "            \"A dog running in a park\",\n",
    "            \"A beautiful sunset over the ocean\",\n",
    "            \"A cat sleeping on a sofa\",\n",
    "            \"A mountain landscape with snow\"\n",
    "        ]\n",
    "        images = generate_images(gan, batch_size=4, captions=test_captions)\n",
    "    \n",
    "    if images is not None:\n",
    "        save_images(images)\n",
    "    \n",
    "    logger.info(\"GigaGAN workflow completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gigagan:Starting GigaGAN workflow in unconditional mode\n",
      "INFO:gigagan:Building unconditional dataset with 2000 samples...\n",
      "INFO:gigagan:Collected 0/2000 samples...\n",
      "INFO:gigagan:Collected 100/2000 samples...\n",
      "INFO:gigagan:Collected 200/2000 samples...\n",
      "INFO:gigagan:Collected 300/2000 samples...\n",
      "INFO:gigagan:Collected 400/2000 samples...\n",
      "INFO:gigagan:Collected 500/2000 samples...\n",
      "INFO:gigagan:Collected 600/2000 samples...\n",
      "INFO:gigagan:Collected 700/2000 samples...\n",
      "INFO:gigagan:Collected 800/2000 samples...\n",
      "INFO:gigagan:Collected 900/2000 samples...\n",
      "INFO:gigagan:Collected 1000/2000 samples...\n",
      "INFO:gigagan:Collected 1100/2000 samples...\n",
      "INFO:gigagan:Collected 1200/2000 samples...\n",
      "INFO:gigagan:Collected 1300/2000 samples...\n",
      "INFO:gigagan:Collected 1400/2000 samples...\n",
      "INFO:gigagan:Collected 1500/2000 samples...\n",
      "INFO:gigagan:Collected 1600/2000 samples...\n",
      "INFO:gigagan:Collected 1700/2000 samples...\n",
      "INFO:gigagan:Collected 1800/2000 samples...\n",
      "INFO:gigagan:Collected 1900/2000 samples...\n",
      "INFO:gigagan:Dataset built in 490.62s with 2000 samples\n",
      "INFO:gigagan:Setting up unconditional GigaGAN model...\n",
      "INFO:gigagan:Model architecture: 19,759,850 generator params, 41,468,868 discriminator params\n",
      "INFO:gigagan:Total parameters: 80,988,568 (61,228,718 trainable)\n",
      "INFO:gigagan:Model size: 308.95 MB\n",
      "INFO:gigagan:Training unconditional GigaGAN for 3000 steps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generator: 19.76M\n",
      "Discriminator: 41.47M\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 3.53 | MSG: -10.70 | VG: 0.00 | D: 3.37 | MSD: 38.70 | VD: 0.00 | GP: 0.00 | SSL: 2.45 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/3000 [01:02<2:35:52,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 6.78 | MSG: -20.80 | VG: 0.00 | D: 1.54 | MSD: 35.46 | VD: 0.00 | GP: 0.00 | SSL: 0.78 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 41/3000 [01:57<2:34:58,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.40 | MSG: -4.90 | VG: 0.00 | D: 3.78 | MSD: 22.23 | VD: 0.00 | GP: 78807.69 | SSL: 0.50 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 61/3000 [02:52<2:33:52,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -7.19 | MSG: 2.83 | VG: 0.00 | D: 9.82 | MSD: 17.25 | VD: 0.00 | GP: 44738.25 | SSL: 0.35 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 81/3000 [03:46<2:32:54,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -10.25 | MSG: 6.06 | VG: 0.00 | D: 13.41 | MSD: 21.53 | VD: 0.00 | GP: 42547.47 | SSL: 0.30 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 100/3000 [04:36<1:56:36,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -3.80 | MSG: 3.28 | VG: 0.00 | D: 8.38 | MSD: 22.62 | VD: 0.00 | GP: 21634.46 | SSL: 0.27 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 121/3000 [05:44<2:30:12,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -2.53 | MSG: -4.21 | VG: 0.00 | D: 10.00 | MSD: 35.66 | VD: 0.00 | GP: 16514.59 | SSL: 0.26 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 141/3000 [06:38<2:28:33,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 5.68 | MSG: -4.79 | VG: 0.00 | D: 7.18 | MSD: 34.42 | VD: 0.00 | GP: 13327.88 | SSL: 0.22 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 161/3000 [07:32<2:27:39,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 5.48 | MSG: -5.70 | VG: 0.00 | D: 6.51 | MSD: 28.47 | VD: 0.00 | GP: 9747.00 | SSL: 0.24 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 181/3000 [08:27<2:26:51,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.34 | MSG: -0.64 | VG: 0.00 | D: 6.59 | MSD: 23.49 | VD: 0.00 | GP: 8974.85 | SSL: 0.21 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/3000 [09:17<1:53:03,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.21 | MSG: -0.57 | VG: 0.00 | D: 5.86 | MSD: 23.88 | VD: 0.00 | GP: 7538.04 | SSL: 0.18 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 221/3000 [10:25<2:25:44,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 3.69 | MSG: 4.57 | VG: 0.00 | D: 3.44 | MSD: 21.27 | VD: 0.00 | GP: 6199.12 | SSL: 0.22 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 241/3000 [11:19<2:24:06,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.45 | MSG: 3.30 | VG: 0.00 | D: 5.16 | MSD: 17.47 | VD: 0.00 | GP: 5253.39 | SSL: 0.19 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 261/3000 [12:14<2:23:20,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.96 | MSG: 3.20 | VG: 0.00 | D: 5.92 | MSD: 17.33 | VD: 0.00 | GP: 5221.27 | SSL: 0.19 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 281/3000 [13:09<2:22:24,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 1.76 | MSG: 4.17 | VG: 0.00 | D: 4.92 | MSD: 17.12 | VD: 0.00 | GP: 4065.02 | SSL: 0.17 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 300/3000 [13:59<1:48:51,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.10 | MSG: 5.43 | VG: 0.00 | D: 5.99 | MSD: 15.29 | VD: 0.00 | GP: 3725.20 | SSL: 0.20 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 321/3000 [15:06<2:20:51,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.59 | MSG: 4.57 | VG: 0.00 | D: 5.67 | MSD: 16.19 | VD: 0.00 | GP: 3664.15 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 341/3000 [16:01<2:19:46,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -2.51 | MSG: 4.55 | VG: 0.00 | D: 6.08 | MSD: 14.63 | VD: 0.00 | GP: 3149.01 | SSL: 0.17 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 361/3000 [16:56<2:17:13,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.94 | MSG: 4.14 | VG: 0.00 | D: 5.57 | MSD: 15.09 | VD: 0.00 | GP: 3026.26 | SSL: 0.19 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 381/3000 [17:50<2:16:21,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.09 | MSG: 4.42 | VG: 0.00 | D: 4.75 | MSD: 15.49 | VD: 0.00 | GP: 2748.62 | SSL: 0.20 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 400/3000 [18:40<1:43:49,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.74 | MSG: 4.21 | VG: 0.00 | D: 5.24 | MSD: 16.34 | VD: 0.00 | GP: 2630.45 | SSL: 0.16 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 421/3000 [19:47<2:15:17,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -2.08 | MSG: 4.43 | VG: 0.00 | D: 4.85 | MSD: 13.84 | VD: 0.00 | GP: 2503.67 | SSL: 0.16 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 441/3000 [20:42<2:14:46,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -2.37 | MSG: 4.79 | VG: 0.00 | D: 5.44 | MSD: 14.24 | VD: 0.00 | GP: 2228.53 | SSL: 0.16 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 461/3000 [21:37<2:13:12,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.56 | MSG: 4.64 | VG: 0.00 | D: 4.87 | MSD: 13.14 | VD: 0.00 | GP: 2455.20 | SSL: 0.18 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 481/3000 [22:32<2:12:03,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.40 | MSG: 4.49 | VG: 0.00 | D: 4.53 | MSD: 14.91 | VD: 0.00 | GP: 1892.05 | SSL: 0.16 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 500/3000 [23:22<1:40:58,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.50 | MSG: 5.54 | VG: 0.00 | D: 5.20 | MSD: 14.18 | VD: 0.00 | GP: 2211.64 | SSL: 0.18 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 521/3000 [24:29<2:09:56,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.53 | MSG: 4.69 | VG: 0.00 | D: 4.60 | MSD: 15.23 | VD: 0.00 | GP: 1837.00 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 541/3000 [25:24<2:08:54,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.66 | MSG: 5.24 | VG: 0.00 | D: 4.70 | MSD: 12.61 | VD: 0.00 | GP: 1788.77 | SSL: 0.18 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 561/3000 [26:19<2:08:10,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.03 | MSG: 4.27 | VG: 0.00 | D: 4.13 | MSD: 14.90 | VD: 0.00 | GP: 1543.32 | SSL: 0.17 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 581/3000 [27:14<2:07:15,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.81 | MSG: 4.28 | VG: 0.00 | D: 3.81 | MSD: 12.85 | VD: 0.00 | GP: 1481.83 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 600/3000 [28:04<1:36:28,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.49 | MSG: 3.57 | VG: 0.00 | D: 3.34 | MSD: 14.52 | VD: 0.00 | GP: 1569.91 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 621/3000 [29:11<2:04:24,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.30 | MSG: 3.36 | VG: 0.00 | D: 3.45 | MSD: 13.98 | VD: 0.00 | GP: 1571.99 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 641/3000 [30:06<2:03:05,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.62 | MSG: 3.86 | VG: 0.00 | D: 3.60 | MSD: 14.60 | VD: 0.00 | GP: 1279.06 | SSL: 0.16 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 661/3000 [31:01<2:02:18,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.98 | MSG: 4.47 | VG: 0.00 | D: 3.76 | MSD: 12.77 | VD: 0.00 | GP: 1192.76 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 681/3000 [31:55<2:01:40,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.56 | MSG: 3.76 | VG: 0.00 | D: 3.37 | MSD: 14.11 | VD: 0.00 | GP: 1188.87 | SSL: 0.16 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 700/3000 [32:45<1:32:44,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.54 | MSG: 4.36 | VG: 0.00 | D: 3.37 | MSD: 12.26 | VD: 0.00 | GP: 1181.05 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 721/3000 [33:53<1:59:45,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.67 | MSG: 3.87 | VG: 0.00 | D: 3.66 | MSD: 13.49 | VD: 0.00 | GP: 1120.83 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 741/3000 [34:48<1:58:21,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.37 | MSG: 2.53 | VG: 0.00 | D: 3.06 | MSD: 13.59 | VD: 0.00 | GP: 1160.41 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 761/3000 [35:43<1:57:19,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -1.02 | MSG: 3.99 | VG: 0.00 | D: 3.63 | MSD: 11.91 | VD: 0.00 | GP: 999.29 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 781/3000 [36:38<1:56:18,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.49 | MSG: 3.83 | VG: 0.00 | D: 3.26 | MSD: 12.97 | VD: 0.00 | GP: 980.67 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 800/3000 [37:28<1:28:38,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.37 | MSG: 3.77 | VG: 0.00 | D: 2.98 | MSD: 14.96 | VD: 0.00 | GP: 1021.11 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 821/3000 [38:35<1:54:24,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.55 | MSG: 3.49 | VG: 0.00 | D: 3.24 | MSD: 11.99 | VD: 0.00 | GP: 932.63 | SSL: 0.17 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 841/3000 [39:30<1:52:40,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.34 | MSG: 3.26 | VG: 0.00 | D: 2.64 | MSD: 14.99 | VD: 0.00 | GP: 940.76 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 861/3000 [40:24<1:51:45,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.39 | MSG: 3.45 | VG: 0.00 | D: 3.09 | MSD: 12.02 | VD: 0.00 | GP: 822.19 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 881/3000 [41:19<1:51:02,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.25 | MSG: 2.48 | VG: 0.00 | D: 2.84 | MSD: 13.45 | VD: 0.00 | GP: 846.32 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 900/3000 [42:08<1:23:49,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.10 | MSG: 2.91 | VG: 0.00 | D: 2.52 | MSD: 11.83 | VD: 0.00 | GP: 755.05 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 921/3000 [43:16<1:49:03,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.60 | MSG: 3.17 | VG: 0.00 | D: 2.79 | MSD: 12.88 | VD: 0.00 | GP: 814.06 | SSL: 0.17 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 941/3000 [44:11<1:48:28,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.39 | MSG: 2.89 | VG: 0.00 | D: 2.36 | MSD: 12.06 | VD: 0.00 | GP: 767.10 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 961/3000 [45:05<1:46:48,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.57 | MSG: 2.63 | VG: 0.00 | D: 2.62 | MSD: 12.53 | VD: 0.00 | GP: 686.43 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 981/3000 [46:00<1:46:08,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.59 | MSG: 2.71 | VG: 0.00 | D: 2.96 | MSD: 11.09 | VD: 0.00 | GP: 656.46 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1000/3000 [46:50<1:21:08,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.03 | MSG: 2.67 | VG: 0.00 | D: 2.60 | MSD: 12.38 | VD: 0.00 | GP: 656.05 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1021/3000 [47:59<1:43:47,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.12 | MSG: 2.96 | VG: 0.00 | D: 3.16 | MSD: 11.00 | VD: 0.00 | GP: 718.99 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1041/3000 [48:54<1:42:32,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.42 | MSG: 2.34 | VG: 0.00 | D: 2.79 | MSD: 12.09 | VD: 0.00 | GP: 639.69 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1061/3000 [49:48<1:41:59,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.27 | MSG: 2.53 | VG: 0.00 | D: 2.58 | MSD: 11.11 | VD: 0.00 | GP: 632.22 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1081/3000 [50:43<1:40:26,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.14 | MSG: 2.83 | VG: 0.00 | D: 2.68 | MSD: 11.83 | VD: 0.00 | GP: 612.04 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1100/3000 [51:33<1:15:57,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.16 | MSG: 2.56 | VG: 0.00 | D: 2.58 | MSD: 10.96 | VD: 0.00 | GP: 604.05 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1121/3000 [52:41<1:37:37,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.14 | MSG: 1.54 | VG: 0.00 | D: 2.63 | MSD: 11.77 | VD: 0.00 | GP: 558.87 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1141/3000 [53:36<1:36:49,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.00 | MSG: 2.02 | VG: 0.00 | D: 2.67 | MSD: 10.85 | VD: 0.00 | GP: 546.38 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1161/3000 [54:30<1:36:03,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.18 | MSG: 2.27 | VG: 0.00 | D: 2.38 | MSD: 11.33 | VD: 0.00 | GP: 554.98 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1181/3000 [55:25<1:35:04,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.11 | MSG: 2.33 | VG: 0.00 | D: 2.65 | MSD: 10.69 | VD: 0.00 | GP: 539.90 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1200/3000 [56:15<1:12:14,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.39 | MSG: 2.04 | VG: 0.00 | D: 2.07 | MSD: 11.18 | VD: 0.00 | GP: 516.69 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1221/3000 [57:23<1:33:04,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.49 | MSG: 2.71 | VG: 0.00 | D: 2.61 | MSD: 12.09 | VD: 0.00 | GP: 512.48 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 1241/3000 [58:17<1:32:09,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.15 | MSG: 1.74 | VG: 0.00 | D: 2.62 | MSD: 10.57 | VD: 0.00 | GP: 473.49 | SSL: 0.15 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1261/3000 [59:12<1:31:01,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.02 | MSG: 1.74 | VG: 0.00 | D: 2.23 | MSD: 11.69 | VD: 0.00 | GP: 510.07 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1281/3000 [1:00:07<1:29:49,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.16 | MSG: 2.21 | VG: 0.00 | D: 2.85 | MSD: 10.33 | VD: 0.00 | GP: 438.12 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1300/3000 [1:00:56<1:07:58,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.02 | MSG: 1.91 | VG: 0.00 | D: 2.70 | MSD: 11.25 | VD: 0.00 | GP: 435.37 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1321/3000 [1:02:04<1:27:09,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.06 | MSG: 1.75 | VG: 0.00 | D: 2.24 | MSD: 10.30 | VD: 0.00 | GP: 438.36 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 1341/3000 [1:02:58<1:26:41,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.10 | MSG: 1.65 | VG: 0.00 | D: 2.27 | MSD: 10.72 | VD: 0.00 | GP: 394.80 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1361/3000 [1:03:53<1:25:48,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.45 | MSG: 2.15 | VG: 0.00 | D: 2.17 | MSD: 10.41 | VD: 0.00 | GP: 430.53 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 1381/3000 [1:04:48<1:24:52,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.00 | MSG: 2.02 | VG: 0.00 | D: 2.09 | MSD: 10.95 | VD: 0.00 | GP: 411.18 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1400/3000 [1:05:38<1:04:37,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.38 | MSG: 2.05 | VG: 0.00 | D: 2.13 | MSD: 10.03 | VD: 0.00 | GP: 364.66 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1421/3000 [1:06:47<1:22:52,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.36 | MSG: 1.82 | VG: 0.00 | D: 2.03 | MSD: 11.63 | VD: 0.00 | GP: 383.59 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1441/3000 [1:07:41<1:22:02,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.07 | MSG: 0.96 | VG: 0.00 | D: 2.01 | MSD: 10.16 | VD: 0.00 | GP: 373.48 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 1461/3000 [1:08:36<1:20:32,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.01 | MSG: 0.92 | VG: 0.00 | D: 1.87 | MSD: 10.32 | VD: 0.00 | GP: 376.74 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1481/3000 [1:09:31<1:19:27,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.01 | MSG: 1.76 | VG: 0.00 | D: 2.23 | MSD: 9.92 | VD: 0.00 | GP: 335.03 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1500/3000 [1:10:21<1:00:20,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.06 | MSG: 1.42 | VG: 0.00 | D: 2.30 | MSD: 10.79 | VD: 0.00 | GP: 342.73 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1521/3000 [1:11:29<1:17:58,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.07 | MSG: 1.88 | VG: 0.00 | D: 2.16 | MSD: 9.75 | VD: 0.00 | GP: 329.56 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 1541/3000 [1:12:24<1:16:21,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.29 | MSG: 0.90 | VG: 0.00 | D: 2.15 | MSD: 10.11 | VD: 0.00 | GP: 330.16 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1561/3000 [1:13:18<1:14:32,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.21 | MSG: 1.33 | VG: 0.00 | D: 2.02 | MSD: 9.82 | VD: 0.00 | GP: 329.33 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1581/3000 [1:14:13<1:13:55,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.04 | MSG: 0.89 | VG: 0.00 | D: 2.04 | MSD: 10.43 | VD: 0.00 | GP: 313.58 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1600/3000 [1:15:02<56:13,  2.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.33 | MSG: 1.11 | VG: 0.00 | D: 2.23 | MSD: 9.78 | VD: 0.00 | GP: 290.69 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1621/3000 [1:16:11<1:12:22,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.11 | MSG: 1.10 | VG: 0.00 | D: 1.68 | MSD: 10.12 | VD: 0.00 | GP: 299.84 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1641/3000 [1:17:06<1:11:18,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.06 | MSG: 1.10 | VG: 0.00 | D: 1.76 | MSD: 9.66 | VD: 0.00 | GP: 287.10 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1661/3000 [1:18:00<1:10:22,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.08 | MSG: 1.22 | VG: 0.00 | D: 2.31 | MSD: 10.32 | VD: 0.00 | GP: 284.43 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1681/3000 [1:18:55<1:09:07,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.41 | MSG: 0.66 | VG: 0.00 | D: 2.21 | MSD: 9.51 | VD: 0.00 | GP: 290.15 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1700/3000 [1:19:45<52:24,  2.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.08 | MSG: 0.79 | VG: 0.00 | D: 2.13 | MSD: 9.86 | VD: 0.00 | GP: 262.05 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1721/3000 [1:20:55<1:07:39,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.07 | MSG: 1.24 | VG: 0.00 | D: 2.01 | MSD: 9.42 | VD: 0.00 | GP: 263.00 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1741/3000 [1:21:49<1:06:08,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.03 | MSG: 0.71 | VG: 0.00 | D: 2.05 | MSD: 9.69 | VD: 0.00 | GP: 266.81 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1761/3000 [1:22:45<1:05:02,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.10 | MSG: 1.04 | VG: 0.00 | D: 1.94 | MSD: 9.62 | VD: 0.00 | GP: 243.38 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1781/3000 [1:23:39<1:03:48,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.05 | MSG: 0.91 | VG: 0.00 | D: 1.93 | MSD: 9.79 | VD: 0.00 | GP: 247.70 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1800/3000 [1:24:29<48:01,  2.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.04 | MSG: 0.78 | VG: 0.00 | D: 2.02 | MSD: 9.32 | VD: 0.00 | GP: 228.90 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1821/3000 [1:25:37<1:01:28,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.68 | MSG: 0.63 | VG: 0.00 | D: 1.76 | MSD: 9.84 | VD: 0.00 | GP: 232.38 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 1841/3000 [1:26:31<1:00:33,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.44 | MSG: 0.96 | VG: 0.00 | D: 1.81 | MSD: 9.19 | VD: 0.00 | GP: 218.82 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1861/3000 [1:27:26<59:34,  3.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.44 | MSG: 1.13 | VG: 0.00 | D: 1.97 | MSD: 9.49 | VD: 0.00 | GP: 234.90 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1881/3000 [1:28:21<59:08,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.05 | MSG: 1.10 | VG: 0.00 | D: 2.05 | MSD: 9.43 | VD: 0.00 | GP: 216.15 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1900/3000 [1:29:11<44:19,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.12 | MSG: 0.90 | VG: 0.00 | D: 1.92 | MSD: 9.58 | VD: 0.00 | GP: 222.29 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1921/3000 [1:30:20<56:55,  3.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.30 | MSG: 0.74 | VG: 0.00 | D: 1.85 | MSD: 9.26 | VD: 0.00 | GP: 207.86 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1941/3000 [1:31:14<55:48,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.20 | MSG: 0.48 | VG: 0.00 | D: 2.12 | MSD: 9.48 | VD: 0.00 | GP: 202.66 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1961/3000 [1:32:09<54:42,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.23 | MSG: 0.91 | VG: 0.00 | D: 1.82 | MSD: 9.22 | VD: 0.00 | GP: 187.25 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1981/3000 [1:33:05<53:35,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.08 | MSG: 1.01 | VG: 0.00 | D: 1.87 | MSD: 9.23 | VD: 0.00 | GP: 190.24 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2000/3000 [1:33:55<40:13,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.41 | MSG: 1.03 | VG: 0.00 | D: 1.73 | MSD: 9.22 | VD: 0.00 | GP: 196.88 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2021/3000 [1:34:59<51:21,  3.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.01 | MSG: 1.00 | VG: 0.00 | D: 2.03 | MSD: 9.08 | VD: 0.00 | GP: 178.64 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2041/3000 [1:35:54<50:08,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.26 | MSG: 0.86 | VG: 0.00 | D: 1.66 | MSD: 8.88 | VD: 0.00 | GP: 186.19 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 2061/3000 [1:36:48<48:40,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.31 | MSG: 0.73 | VG: 0.00 | D: 1.93 | MSD: 9.19 | VD: 0.00 | GP: 178.90 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2081/3000 [1:37:43<47:49,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.38 | MSG: 1.32 | VG: 0.00 | D: 1.81 | MSD: 8.95 | VD: 0.00 | GP: 172.85 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2100/3000 [1:38:32<35:56,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.47 | MSG: 0.98 | VG: 0.00 | D: 2.59 | MSD: 8.99 | VD: 0.00 | GP: 163.74 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 2121/3000 [1:39:40<46:10,  3.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.62 | MSG: 1.31 | VG: 0.00 | D: 1.75 | MSD: 9.14 | VD: 0.00 | GP: 172.01 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 2141/3000 [1:40:35<44:55,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.06 | MSG: 0.98 | VG: 0.00 | D: 2.08 | MSD: 9.14 | VD: 0.00 | GP: 158.65 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2161/3000 [1:41:30<43:57,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.05 | MSG: 0.86 | VG: 0.00 | D: 1.85 | MSD: 8.82 | VD: 0.00 | GP: 160.54 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2181/3000 [1:42:25<42:55,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.26 | MSG: 0.59 | VG: 0.00 | D: 1.81 | MSD: 8.75 | VD: 0.00 | GP: 162.62 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2200/3000 [1:43:15<32:14,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.50 | MSG: 0.40 | VG: 0.00 | D: 1.74 | MSD: 8.85 | VD: 0.00 | GP: 165.30 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 2221/3000 [1:44:24<40:54,  3.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.13 | MSG: -0.19 | VG: 0.00 | D: 1.82 | MSD: 8.90 | VD: 0.00 | GP: 161.26 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 2241/3000 [1:45:19<39:40,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.05 | MSG: 0.68 | VG: 0.00 | D: 2.00 | MSD: 8.69 | VD: 0.00 | GP: 139.87 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 2261/3000 [1:46:14<38:40,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.34 | MSG: 0.22 | VG: 0.00 | D: 1.66 | MSD: 8.97 | VD: 0.00 | GP: 141.77 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 2281/3000 [1:47:08<37:35,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.20 | MSG: 0.65 | VG: 0.00 | D: 1.64 | MSD: 8.87 | VD: 0.00 | GP: 135.22 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2300/3000 [1:47:58<28:07,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.35 | MSG: 0.32 | VG: 0.00 | D: 1.90 | MSD: 9.07 | VD: 0.00 | GP: 138.86 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2321/3000 [1:49:06<35:26,  3.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.02 | MSG: 0.84 | VG: 0.00 | D: 1.93 | MSD: 8.53 | VD: 0.00 | GP: 132.44 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2341/3000 [1:50:00<34:17,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.03 | MSG: 0.12 | VG: 0.00 | D: 1.90 | MSD: 8.82 | VD: 0.00 | GP: 138.17 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 2361/3000 [1:50:55<33:24,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.02 | MSG: 0.77 | VG: 0.00 | D: 1.99 | MSD: 8.58 | VD: 0.00 | GP: 138.39 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 2381/3000 [1:51:50<32:39,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.03 | MSG: 0.53 | VG: 0.00 | D: 1.91 | MSD: 8.92 | VD: 0.00 | GP: 127.52 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2400/3000 [1:52:40<24:07,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.05 | MSG: 0.24 | VG: 0.00 | D: 1.91 | MSD: 8.40 | VD: 0.00 | GP: 119.90 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2421/3000 [1:53:48<30:22,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.21 | MSG: 0.66 | VG: 0.00 | D: 1.87 | MSD: 8.88 | VD: 0.00 | GP: 123.68 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 2441/3000 [1:54:43<29:19,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.09 | MSG: 1.40 | VG: 0.00 | D: 1.84 | MSD: 8.62 | VD: 0.00 | GP: 118.34 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 2461/3000 [1:55:37<28:03,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.25 | MSG: 0.48 | VG: 0.00 | D: 1.69 | MSD: 8.75 | VD: 0.00 | GP: 119.15 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 2481/3000 [1:56:32<27:16,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.39 | MSG: 0.42 | VG: 0.00 | D: 1.81 | MSD: 8.62 | VD: 0.00 | GP: 115.87 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 2500/3000 [1:57:21<20:06,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.16 | MSG: 0.37 | VG: 0.00 | D: 1.87 | MSD: 8.65 | VD: 0.00 | GP: 113.75 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 2521/3000 [1:58:30<25:02,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.19 | MSG: 0.24 | VG: 0.00 | D: 1.70 | MSD: 8.55 | VD: 0.00 | GP: 115.89 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 2541/3000 [1:59:25<23:59,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.51 | MSG: 0.18 | VG: 0.00 | D: 1.49 | MSD: 8.88 | VD: 0.00 | GP: 110.82 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 2561/3000 [2:00:19<22:55,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.25 | MSG: 0.37 | VG: 0.00 | D: 2.06 | MSD: 8.73 | VD: 0.00 | GP: 109.43 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 2581/3000 [2:01:14<21:52,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.13 | MSG: 0.41 | VG: 0.00 | D: 1.93 | MSD: 8.46 | VD: 0.00 | GP: 104.60 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2601/3000 [2:02:08<20:50,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.21 | MSG: 0.48 | VG: 0.00 | D: 1.85 | MSD: 8.70 | VD: 0.00 | GP: 97.85 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2621/3000 [2:03:03<19:48,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.45 | MSG: 0.64 | VG: 0.00 | D: 1.88 | MSD: 8.62 | VD: 0.00 | GP: 101.18 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2641/3000 [2:03:58<18:49,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.36 | MSG: 0.78 | VG: 0.00 | D: 1.79 | MSD: 8.53 | VD: 0.00 | GP: 99.96 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 2661/3000 [2:04:53<17:43,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.12 | MSG: 0.09 | VG: 0.00 | D: 1.58 | MSD: 8.68 | VD: 0.00 | GP: 98.88 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 2681/3000 [2:05:47<16:36,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.09 | MSG: 0.35 | VG: 0.00 | D: 1.90 | MSD: 8.56 | VD: 0.00 | GP: 94.23 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 2701/3000 [2:06:42<15:37,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.29 | MSG: 0.45 | VG: 0.00 | D: 1.85 | MSD: 8.71 | VD: 0.00 | GP: 94.89 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 2721/3000 [2:07:36<14:33,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.43 | MSG: 0.65 | VG: 0.00 | D: 1.95 | MSD: 8.29 | VD: 0.00 | GP: 90.48 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 2741/3000 [2:08:31<13:34,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.29 | MSG: 0.25 | VG: 0.00 | D: 1.61 | MSD: 8.47 | VD: 0.00 | GP: 95.12 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 2761/3000 [2:09:26<12:34,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.34 | MSG: 1.06 | VG: 0.00 | D: 1.61 | MSD: 8.70 | VD: 0.00 | GP: 93.00 | SSL: 0.13 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2781/3000 [2:10:21<11:25,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.31 | MSG: 0.78 | VG: 0.00 | D: 1.63 | MSD: 8.49 | VD: 0.00 | GP: 91.08 | SSL: 0.14 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2801/3000 [2:11:15<10:21,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.23 | MSG: 0.64 | VG: 0.00 | D: 1.75 | MSD: 8.41 | VD: 0.00 | GP: 89.12 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 2821/3000 [2:12:10<09:19,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.46 | MSG: -0.02 | VG: 0.00 | D: 1.68 | MSD: 8.69 | VD: 0.00 | GP: 82.81 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 2841/3000 [2:13:04<08:19,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.14 | MSG: 0.22 | VG: 0.00 | D: 1.75 | MSD: 8.49 | VD: 0.00 | GP: 83.76 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2861/3000 [2:13:59<07:16,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.16 | MSG: 0.19 | VG: 0.00 | D: 1.87 | MSD: 8.51 | VD: 0.00 | GP: 83.31 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 2881/3000 [2:14:54<06:15,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.46 | MSG: 0.20 | VG: 0.00 | D: 1.83 | MSD: 8.47 | VD: 0.00 | GP: 81.32 | SSL: 0.11 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 2901/3000 [2:15:48<05:09,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.09 | MSG: 0.95 | VG: 0.00 | D: 1.97 | MSD: 8.56 | VD: 0.00 | GP: 84.99 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 2921/3000 [2:16:43<04:06,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.03 | MSG: 0.66 | VG: 0.00 | D: 1.78 | MSD: 8.31 | VD: 0.00 | GP: 75.56 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 2941/3000 [2:17:37<03:05,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.23 | MSG: -0.09 | VG: 0.00 | D: 1.73 | MSD: 8.64 | VD: 0.00 | GP: 77.14 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 2961/3000 [2:18:32<02:02,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.25 | MSG: 0.27 | VG: 0.00 | D: 1.75 | MSD: 8.64 | VD: 0.00 | GP: 73.84 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 2981/3000 [2:19:26<00:59,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: -0.08 | MSG: 0.80 | VG: 0.00 | D: 1.82 | MSD: 8.45 | VD: 0.00 | GP: 76.64 | SSL: 0.10 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [2:20:16<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: 0.51 | MSG: 0.36 | VG: 0.00 | D: 1.56 | MSD: 8.58 | VD: 0.00 | GP: 80.13 | SSL: 0.12 | CL: 0.00 | MAL: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [2:20:26,  2.81s/it]                          \n",
      "INFO:gigagan:Training completed for 3000 steps\n",
      "INFO:gigagan:Generating 4 images unconditionally\n",
      "INFO:gigagan:Saving image to gigagan-results/generated_image_0.png\n",
      "INFO:gigagan:Saving image to gigagan-results/generated_image_1.png\n",
      "INFO:gigagan:Saving image to gigagan-results/generated_image_2.png\n",
      "INFO:gigagan:Saving image to gigagan-results/generated_image_3.png\n",
      "INFO:gigagan:GigaGAN workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete 3000 training steps\n"
     ]
    }
   ],
   "source": [
    "# For unconditional training:\n",
    "run_gigagan_workflow(unconditional=True, num_samples=2000, training_steps=3000)\n",
    "\n",
    "# For conditional training:\n",
    "# run_gigagan_workflow(unconditional=False, num_samples=2000, training_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cX-qK0JiJuw2"
   },
   "outputs": [],
   "source": [
    "# Cell 10: Training profiling function\n",
    "'''\n",
    "def profile_training(gan, dataloader, steps=10, grad_accum_every=8):\n",
    "    \"\"\"Profile the training process with detailed metrics\"\"\"\n",
    "    logger.info(f\"Profiling training for {steps} steps (grad_accum_every={grad_accum_every})...\")\n",
    "\n",
    "    # Set up the dataloader\n",
    "    gan.set_dataloader(dataloader)\n",
    "\n",
    "    # Clear cache before profiling\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # Record initial memory state\n",
    "    initial_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
    "\n",
    "    # Warmup step (not measured)\n",
    "    logger.info(\"Performing warmup step...\")\n",
    "    gan(steps=1, grad_accum_every=grad_accum_every)\n",
    "\n",
    "    # Wait for GPU operations to complete\n",
    "    #torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    # Begin profiling\n",
    "    logger.info(f\"Starting profiled training run...\")\n",
    "\n",
    "    # Use PyTorch Profiler for detailed performance analysis\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True,\n",
    "        with_flops=True\n",
    "    ) as prof:\n",
    "        # Record start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run training\n",
    "        gan(steps=steps, grad_accum_every=grad_accum_every)\n",
    "\n",
    "        # Wait for GPU operations to complete\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Record end time\n",
    "        end_time = time.time()\n",
    "\n",
    "    # Clear cache between chunks\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    total_time = end_time - start_time\n",
    "    avg_step_time = total_time / steps\n",
    "    samples_per_second = dataloader.batch_size * grad_accum_every / avg_step_time\n",
    "\n",
    "    # Memory metrics\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024 * 1024)  # MB\n",
    "    memory_increase = peak_memory - initial_memory\n",
    "\n",
    "    # Save profiler results\n",
    "    logger.info(\"Saving profiler trace and stats...\")\n",
    "    prof.export_chrome_trace(\"profiling_results/training_trace.json\")\n",
    "\n",
    "    # Extract key metrics from profiler\n",
    "    with open(\"profiling_results/operator_stats.txt\", \"w\") as f:\n",
    "        f.write(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=50))\n",
    "\n",
    "    # Create memory timeline\n",
    "    prof_table = prof.key_averages()\n",
    "\n",
    "    # Record and save metrics\n",
    "    training_stats = {\n",
    "        \"total_steps\": steps,\n",
    "        \"grad_accum_every\": grad_accum_every,\n",
    "        \"effective_batch_size\": dataloader.batch_size * grad_accum_every,\n",
    "        \"total_time_seconds\": total_time,\n",
    "        \"avg_step_time_seconds\": avg_step_time,\n",
    "        \"samples_per_second\": samples_per_second,\n",
    "        \"initial_memory_mb\": initial_memory,\n",
    "        \"peak_memory_mb\": peak_memory,\n",
    "        \"memory_increase_mb\": memory_increase\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Training profile: {steps} steps in {total_time:.2f}s ({avg_step_time:.4f}s/step)\")\n",
    "    logger.info(f\"Throughput: {samples_per_second:.2f} samples/sec\")\n",
    "    logger.info(f\"Memory usage: {peak_memory:.2f} MB peak ({memory_increase:.2f} MB increase)\")\n",
    "\n",
    "    with open(\"profiling_results/training_stats.json\", \"w\") as f:\n",
    "        json.dump(training_stats, f, indent=2)\n",
    "\n",
    "    return training_stats\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "uYyca87MKTx2"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def profile_inference(gan, captions, num_runs=10):\n",
    "    \"\"\"Profile the generator inference performance\"\"\"\n",
    "    logger.info(f\"Profiling inference for {num_runs} runs...\")\n",
    "\n",
    "    # Clear cache before profiling\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # Warmup (not measured)\n",
    "    with torch.no_grad():\n",
    "        _ = gan.generate(batch_size=1, texts=[captions[0]])\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # Collect timing data\n",
    "    inference_times = []\n",
    "    batch_sizes = [1, 2, 4]  # Test different batch sizes\n",
    "    results = {}\n",
    "\n",
    "    # First profile single images\n",
    "    logger.info(\"Profiling individual caption generation...\")\n",
    "    for caption in captions:\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            images = gan.generate(batch_size=1, texts=[caption])\n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "\n",
    "        inference_time = end_time - start_time\n",
    "        inference_times.append(inference_time)\n",
    "        logger.info(f\"Caption '{caption[:20]}...': {inference_time:.4f}s\")\n",
    "\n",
    "    # Record single image stats\n",
    "    single_image_time = sum(inference_times) / len(inference_times)\n",
    "\n",
    "    # Now profile different batch sizes\n",
    "    for batch_size in batch_sizes:\n",
    "        batch_times = []\n",
    "        logger.info(f\"Profiling batch_size={batch_size}...\")\n",
    "\n",
    "        for _ in range(num_runs):\n",
    "            batch_captions = [captions[0]] * batch_size  # Use same caption for batch\n",
    "\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                images = gan.generate(batch_size=batch_size, texts=batch_captions)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "\n",
    "            batch_time = end_time - start_time\n",
    "            batch_times.append(batch_time)\n",
    "\n",
    "        # Calculate stats for this batch size\n",
    "        avg_time = sum(batch_times) / len(batch_times)\n",
    "        per_image_time = avg_time / batch_size\n",
    "        images_per_sec = batch_size / avg_time\n",
    "\n",
    "        results[f\"batch_{batch_size}\"] = {\n",
    "            \"total_time\": avg_time,\n",
    "            \"per_image_time\": per_image_time,\n",
    "            \"images_per_sec\": images_per_sec\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Batch {batch_size}: {avg_time:.4f}s total, {per_image_time:.4f}s per image\")\n",
    "\n",
    "    # Get memory stats\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / (1024 * 1024)  # MB\n",
    "\n",
    "    # Profile with PyTorch Profiler for operator breakdown\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True\n",
    "    ) as prof:\n",
    "        with torch.no_grad():\n",
    "            images = gan.generate(batch_size=1, texts=[captions[0]])\n",
    "\n",
    "    # Save profiler results\n",
    "    prof.export_chrome_trace(\"profiling_results/inference_trace.json\")\n",
    "\n",
    "    with open(\"profiling_results/inference_operator_stats.txt\", \"w\") as f:\n",
    "        f.write(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))\n",
    "\n",
    "    # Combine all results\n",
    "    inference_stats = {\n",
    "        \"single_image_time\": single_image_time,\n",
    "        \"images_per_second\": 1 / single_image_time,\n",
    "        \"peak_memory_mb\": peak_memory,\n",
    "        \"batch_scaling\": results\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Inference profile: {single_image_time:.4f}s per image\")\n",
    "    logger.info(f\"Memory usage: {peak_memory:.2f} MB peak\")\n",
    "\n",
    "    with open(\"profiling_results/inference_stats.json\", \"w\") as f:\n",
    "        json.dump(inference_stats, f, indent=2)\n",
    "\n",
    "    return inference_stats, images\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MBUgf1hsKUIt"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def profile_generated_images(images):\n",
    "    \"\"\"Analyze quality metrics of generated images\"\"\"\n",
    "    logger.info(\"Profiling generated image quality...\")\n",
    "\n",
    "    # Convert to numpy for analysis\n",
    "    if images.is_cuda:\n",
    "        images = images.cpu()\n",
    "    images_np = images.detach().numpy()\n",
    "\n",
    "    # Basic image statistics\n",
    "    min_val = float(np.min(images_np))\n",
    "    max_val = float(np.max(images_np))\n",
    "    mean_val = float(np.mean(images_np))\n",
    "    std_val = float(np.std(images_np))\n",
    "\n",
    "    # Check for blank or low contrast images\n",
    "    value_range = max_val - min_val\n",
    "    is_blank = value_range < 0.1\n",
    "\n",
    "    # Channel-wise statistics\n",
    "    channel_stats = {}\n",
    "    for i, channel_name in enumerate(['red', 'green', 'blue']):\n",
    "        channel = images_np[:, i, :, :]\n",
    "        channel_stats[channel_name] = {\n",
    "            \"min\": float(np.min(channel)),\n",
    "            \"max\": float(np.max(channel)),\n",
    "            \"mean\": float(np.mean(channel)),\n",
    "            \"std\": float(np.std(channel))\n",
    "        }\n",
    "\n",
    "    # Save histograms\n",
    "    '''\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(len(images), 3)):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        for c, color in enumerate(['red', 'green', 'blue']):\n",
    "            plt.hist(images_np[i, c].flatten(), bins=50, alpha=0.5, color=color, label=color)\n",
    "        plt.title(f\"Image {i+1} Histogram\")\n",
    "        plt.xlabel(\"Pixel Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"profiling_results/image_histograms.png\")\n",
    "    '''\n",
    "    # Record results\n",
    "    image_quality = {\n",
    "        \"overall\": {\n",
    "            \"min_value\": min_val,\n",
    "            \"max_value\": max_val,\n",
    "            \"mean_value\": mean_val,\n",
    "            \"std_value\": std_val,\n",
    "            \"value_range\": value_range,\n",
    "            \"appears_blank\": bool(is_blank)\n",
    "        },\n",
    "        \"channels\": channel_stats\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Image quality: range={min_val:.4f} to {max_val:.4f}, mean={mean_val:.4f}\")\n",
    "    if is_blank:\n",
    "        logger.warning(\"WARNING: Images appear to be blank or very low contrast!\")\n",
    "\n",
    "    with open(\"profiling_results/image_quality.json\", \"w\") as f:\n",
    "        json.dump(image_quality, f, indent=2)\n",
    "\n",
    "    return image_quality\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "a5wodG2BKZcz"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def generate_from_caption(gan, caption, num_images=1):\n",
    "    \"\"\"Generate images from caption with timing\"\"\"\n",
    "    logger.info(f\"Generating {num_images} image(s) for caption: '{caption}'\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        images = gan.generate(batch_size=num_images, texts=[caption] * num_images)\n",
    "    generation_time = time.time() - start_time\n",
    "\n",
    "    logger.info(f\"Generation completed in {generation_time:.4f}s\")\n",
    "\n",
    "    return images, generation_time\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "0VkxOwiYKcui"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \"\"\"Visualize images with proper denormalization\"\"\"\\n    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\\n\\n    # Ensure axes is always iterable\\n    if len(images) == 1:\\n        axes = [axes]\\n\\n    for ax, img in zip(axes, images):\\n        img_np = (img.clamp(-1, 1) * 0.5 + 0.5).detach().cpu().numpy()\\n        ax.imshow(np.transpose(img_np, (1, 2, 0)))\\n        ax.axis(\"off\")\\n\\n    plt.tight_layout()\\n    plt.savefig(\"profiling_results/generated_samples.png\")\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def visualize_images(images):\n",
    "    pass\n",
    "'''\n",
    "    \"\"\"Visualize images with proper denormalization\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "\n",
    "    # Ensure axes is always iterable\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img in zip(axes, images):\n",
    "        img_np = (img.clamp(-1, 1) * 0.5 + 0.5).detach().cpu().numpy()\n",
    "        ax.imshow(np.transpose(img_np, (1, 2, 0)))\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"profiling_results/generated_samples.png\")\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bu5kuBp4LpVE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "051984134e66460584306a7136f18fb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2f42a2818ee4f4da258e16f33b75f25",
       "IPY_MODEL_1d09d81fba274e0b937a57688bdc5d49",
       "IPY_MODEL_fbdf6e208e6647e79852bfdbe0e58e18"
      ],
      "layout": "IPY_MODEL_27d1f1aeec0b4b3abb6dc6303e2cc937"
     }
    },
    "0ea7f708e10b42d2a1c8327d80c49d86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1007ffa7a42341af8d2aa5d0411d7573": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "106c9aeb02904aca894b391f930fb915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7446b9c51c9a4ab481e80f05bfa9cf8c",
      "placeholder": "​",
      "style": "IPY_MODEL_350bc3d681e44cba8c5b8ba0306c9ab5",
      "value": " 605M/605M [00:08&lt;00:00, 69.2MB/s]"
     }
    },
    "166196a8780949588af843711d61990b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d09d81fba274e0b937a57688bdc5d49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ea7f708e10b42d2a1c8327d80c49d86",
      "max": 2705,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_166196a8780949588af843711d61990b",
      "value": 2705
     }
    },
    "27d1f1aeec0b4b3abb6dc6303e2cc937": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c0d9c3451714848903c995591cec4f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fca778cfd204fc4ab4dc5889f5cd7ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bff8228516cc44959f11f3869643ad89",
      "placeholder": "​",
      "style": "IPY_MODEL_2c0d9c3451714848903c995591cec4f3",
      "value": "open_clip_model.safetensors: 100%"
     }
    },
    "350bc3d681e44cba8c5b8ba0306c9ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "617dc048584e49ab9a47c86a2ac74336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7446b9c51c9a4ab481e80f05bfa9cf8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86e7091f6af144c29d8528798cd7d8de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb69eab07e294831a1d5e8dfd46de5f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be89926d107d417f889a3a1d012fefdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bff8228516cc44959f11f3869643ad89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f42a2818ee4f4da258e16f33b75f25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd3ded79b20d47dcb96e62a76f96935e",
      "placeholder": "​",
      "style": "IPY_MODEL_617dc048584e49ab9a47c86a2ac74336",
      "value": "README.md: 100%"
     }
    },
    "c8c7f3cb584e41379c392cca00fe0401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3ded79b20d47dcb96e62a76f96935e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d24c48a6af3049318e5ed8438c99d0f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2fca778cfd204fc4ab4dc5889f5cd7ef",
       "IPY_MODEL_d9104cc68a8542daab09fcf5a5f446c5",
       "IPY_MODEL_106c9aeb02904aca894b391f930fb915"
      ],
      "layout": "IPY_MODEL_86e7091f6af144c29d8528798cd7d8de"
     }
    },
    "d9104cc68a8542daab09fcf5a5f446c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1007ffa7a42341af8d2aa5d0411d7573",
      "max": 605143284,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be89926d107d417f889a3a1d012fefdb",
      "value": 605143284
     }
    },
    "fbdf6e208e6647e79852bfdbe0e58e18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb69eab07e294831a1d5e8dfd46de5f2",
      "placeholder": "​",
      "style": "IPY_MODEL_c8c7f3cb584e41379c392cca00fe0401",
      "value": " 2.71k/2.71k [00:00&lt;00:00, 102kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
